{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:34:42.695419Z",
     "iopub.status.busy": "2025-07-14T15:34:42.695146Z",
     "iopub.status.idle": "2025-07-14T15:34:42.699318Z",
     "shell.execute_reply": "2025-07-14T15:34:42.698606Z",
     "shell.execute_reply.started": "2025-07-14T15:34:42.695399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "working_on_kaggle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:34:45.582408Z",
     "iopub.status.busy": "2025-07-14T15:34:45.582010Z",
     "iopub.status.idle": "2025-07-14T15:35:07.586008Z",
     "shell.execute_reply": "2025-07-14T15:35:07.585244Z",
     "shell.execute_reply.started": "2025-07-14T15:34:45.582353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "repo_name = \"PDLPR-algorithm\"\n",
    "username = \"iamlucaconti\"\n",
    "\n",
    "if working_on_kaggle:\n",
    "    !pip install --quiet gdown\n",
    "    !apt-get install -y fonts-noto-cjk > /dev/null\n",
    "\n",
    "    import os\n",
    "    from getpass import getpass\n",
    "    \n",
    "    token = getpass('Your GitHub token: ')\n",
    "    \n",
    "    git_url = f\"https://{username}:{token}@github.com/iamlucaconti/{repo_name}.git\"\n",
    "    os.system(f\"git clone {git_url} /kaggle/working/{repo_name}\")\n",
    "    %cd PDLPR-algorithm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:35:07.587615Z",
     "iopub.status.busy": "2025-07-14T15:35:07.587343Z",
     "iopub.status.idle": "2025-07-14T15:35:17.590531Z",
     "shell.execute_reply": "2025-07-14T15:35:17.589927Z",
     "shell.execute_reply.started": "2025-07-14T15:35:07.587593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from tqdm import tqdm\n",
    "import gdown\n",
    "import tarfile\n",
    "from PIL import Image\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset \n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('./scr/')\n",
    "from pdlpr import PDLPR \n",
    "from trainer import train, set_seed, evaluate_model\n",
    "from augmentation import RandomMotionBlur, RandomGaussianBlur, AddNoise, SimulateDistance, AddFog, MatrixEffect, RandomLightBeam, RandomColorPad, BluePlateHighlight, BlockShiftTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T20:49:52.257237Z",
     "iopub.status.busy": "2025-07-14T20:49:52.256960Z",
     "iopub.status.idle": "2025-07-14T20:49:52.266782Z",
     "shell.execute_reply": "2025-07-14T20:49:52.266038Z",
     "shell.execute_reply.started": "2025-07-14T20:49:52.257215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NUM_WORKERS = 0\n",
    "SEED = 42\n",
    "BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 5\n",
    "VAL_SPLIT_SIZE = 0.2\n",
    "NUM_SAMPLES = 50000\n",
    "num_epochs = 20\n",
    "lr = 0.8*1e-4  # da 1 a 20 1e-4, da 21 a 40 0.8*1e-4, da 41 a 60 (0.8)^2*1e^-4\n",
    "lr_decay_factor = 0.9  \n",
    "lr_decay_epochs = 20\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "save_checkpoint_path = \"pdlpr_checkpoints/\" # or None\n",
    "name_checkpoint = \"checkpoint_epoch80.pt\" # or None\n",
    "\n",
    "if name_checkpoint is not None:\n",
    "    load_checkpoint_path =  os.path.join(save_checkpoint_path, name_checkpoint) \n",
    "else:\n",
    "    load_checkpoint_path = None\n",
    "    \n",
    "extract_path = 'dataset'\n",
    "output_path = 'dataset/ccpd_subset_base.tar'\n",
    "folder_path = os.path.join(extract_path, 'ccpd_subset_base', 'train')\n",
    "cropped_folder = \"dataset/ccpd_cropped\"\n",
    "font_path =  \"C:/Windows/Fonts/msyh.ttc\"\n",
    "\n",
    "\n",
    "kaggle_working_folder = '/kaggle/working/' + repo_name\n",
    "if working_on_kaggle:\n",
    "    NUM_WORKERS = 2\n",
    "    print(\"Creating \", save_checkpoint_path)\n",
    "    save_checkpoint_path = os.path.join(kaggle_working_folder, save_checkpoint_path)\n",
    "    os.makedirs(save_checkpoint_path, exist_ok=True)\n",
    "    \n",
    "    if load_checkpoint_path is not None:\n",
    "        load_checkpoint_path = os.path.join(save_checkpoint_path, name_checkpoint)\n",
    "\n",
    "    \n",
    "    output_path = os.path.join(kaggle_working_folder, output_path)\n",
    "    extract_path = os.path.join(kaggle_working_folder, extract_path)\n",
    "    folder_path = os.path.join(extract_path, 'ccpd_subset_base', 'train')\n",
    "    cropped_folder = os.path.join(kaggle_working_folder, cropped_folder)\n",
    "    font_path = \"/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc\"\n",
    "    \n",
    "prop = fm.FontProperties(fname=font_path)\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "os.makedirs(cropped_folder, exist_ok=True)\n",
    "\n",
    "if load_checkpoint_path is not None and not os.path.isfile(load_checkpoint_path):\n",
    "    raise FileNotFoundError(f\"Checkpoint file not found: {load_checkpoint_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:36:05.397970Z",
     "iopub.status.busy": "2025-07-14T15:36:05.397680Z",
     "iopub.status.idle": "2025-07-14T15:36:05.419698Z",
     "shell.execute_reply": "2025-07-14T15:36:05.419089Z",
     "shell.execute_reply.started": "2025-07-14T15:36:05.397952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\",\n",
    "             \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N',\n",
    "             'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'O']\n",
    "\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R',\n",
    "       'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "unique_chars = set(provinces[:-1] + alphabets[:-1] + ads[:-1])  # escludi 'O'\n",
    "char_list = sorted(list(unique_chars))  # ordinamento per coerenza\n",
    "char_list = [\"-\"] + char_list\n",
    "char2idx = {char: i for i, char in enumerate(char_list)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "\n",
    "num_classes = len(char_list)\n",
    "print(\"Num classes: \", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:36:05.421119Z",
     "iopub.status.busy": "2025-07-14T15:36:05.420911Z",
     "iopub.status.idle": "2025-07-14T15:36:05.443449Z",
     "shell.execute_reply": "2025-07-14T15:36:05.442644Z",
     "shell.execute_reply.started": "2025-07-14T15:36:05.421103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def decode_plate(s):\n",
    "    idx   = list(map(int, s.split(\"_\")))\n",
    "    try:\n",
    "        return provinces[idx[0]] + alphabets[idx[1]] + \"\".join(ads[i] for i in idx[2:])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def split_bbox(bbox_str):\n",
    "    # Split on one or more underscores\n",
    "    tokens = re.split(r'_+', bbox_str)\n",
    "    if len(tokens) == 4 and all(t.isdigit() for t in tokens):\n",
    "        return tuple(map(int, tokens))\n",
    "    return (None,) * 4\n",
    "\n",
    "def crop_and_resize(img, x1, y1, x2, y2):\n",
    "    # Controlla che il bounding box sia valido\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    \n",
    "    # Ritaglia\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Controlla che l'immagine ritagliata non sia vuota\n",
    "    if cropped_img.size == 0:\n",
    "        return None\n",
    "\n",
    "    # Resize a 48x144\n",
    "    try:\n",
    "        return cv2.resize(cropped_img, (144, 48))\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def decode_ccpd_label(label_str, provinces, alphabets, ads):\n",
    "    \"\"\"Decodifica stringa del tipo '0_0_22_27_27_33_16' in targa es. '皖AWWX6G' \"\"\"\n",
    "    indices = list(map(int, label_str.strip().split('_')))\n",
    "    if len(indices) != 7:\n",
    "        raise ValueError(\"Label must contain 7 indices\")\n",
    "\n",
    "    province = provinces[indices[0]]\n",
    "    alphabet = alphabets[indices[1]]\n",
    "    ad_chars = [ads[i] for i in indices[2:]]\n",
    "\n",
    "    return province + alphabet + ''.join(ad_chars)\n",
    "\n",
    "def encode_plate(plate_str, char2idx):\n",
    "    \"\"\"Converte la stringa '皖AWWX6G' in lista di indici [3, 12, 30, 30, ...]\"\"\"\n",
    "    return [char2idx[c] for c in plate_str]\n",
    "\n",
    "def decode_plate_from_list(label_indices, idx2char):\n",
    "    \"\"\"Converte una lista di indici [3, 12, 30, ...] nella stringa '皖AWWX6G'\"\"\"\n",
    "    return ''.join([idx2char[i] for i in label_indices])\n",
    "\n",
    "def greedy_decode(logits, blank_index, idx2char):\n",
    "    preds = logits.argmax(dim=2)  # (B, T)\n",
    "    decoded_batch = []\n",
    "    for pred in preds:\n",
    "        chars = []\n",
    "        prev = None\n",
    "        for p in pred:\n",
    "            p = p.item()\n",
    "            if p != blank_index and p != prev:\n",
    "                chars.append(idx2char[p])\n",
    "            prev = p\n",
    "        decoded_batch.append(''.join(chars))\n",
    "    return decoded_batch\n",
    "\n",
    "\n",
    "def download_and_extract_dataset(url, output_path, extract_path, extracted_folder_path):\n",
    "    \"\"\"\n",
    "    Downloads and extracts a dataset if not already present.\n",
    "\n",
    "    Args:\n",
    "        url (str): Google Drive URL of the dataset.\n",
    "        output_path (str): Path where the .tar file will be saved.\n",
    "        extract_path (str): Directory where the archive will be extracted.\n",
    "        extracted_folder_path (str): Expected folder resulting from extraction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Download the dataset if it doesn't already exist\n",
    "    if not os.path.exists(output_path):\n",
    "        print(\"Downloading the dataset...\")\n",
    "        gdown.download(url, output_path, fuzzy=True, quiet=False)\n",
    "    else:\n",
    "        print(\"Dataset already exists, download skipped.\")\n",
    "\n",
    "    # Extract the dataset if the folder doesn't already exist\n",
    "    if not os.path.exists(extracted_folder_path):\n",
    "        print(\"Extracting the dataset...\")\n",
    "        os.makedirs(extract_path, exist_ok=True)\n",
    "        with tarfile.open(output_path) as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "        print(\"Extraction completed.\")\n",
    "    else:\n",
    "        print(\"Dataset folder already exists, extraction skipped.\")\n",
    "\n",
    "\n",
    "def create_dataframe(folder_path, char2idx):\n",
    "    all_files = sorted(os.listdir(folder_path))\n",
    "    jpg_files = [f for f in all_files if f.endswith('.jpg')]\n",
    "\n",
    "    rows = []\n",
    "    for fname in jpg_files:\n",
    "        parts = fname[:-4].split(\"-\")\n",
    "        if len(parts) < 6:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            x1, y1, x2, y2 = split_bbox(parts[2])\n",
    "            plate = decode_plate(parts[4])\n",
    "            label = encode_plate(plate, char2idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Errore con file {fname}: {e}\")\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"image_path\": os.path.join(folder_path, fname),\n",
    "            \"x1_bbox\": x1, \"y1_bbox\": y1,\n",
    "            \"x2_bbox\": x2, \"y2_bbox\": y2,\n",
    "            \"plate_number\": plate,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def create_cropped_dataframe(df, cropped_folder):\n",
    "    \"\"\"\n",
    "    Crea un nuovo DataFrame con le immagini ritagliate e ridimensionate.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame originale con bounding box e info.\n",
    "        cropped_folder (str): Cartella dove salvare le immagini ritagliate.\n",
    "        crop_and_resize_fn (function): Funzione che riceve (img, x1, y1, x2, y2) e restituisce l'immagine ritagliata e ridimensionata.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Nuovo DataFrame con path immagini ritagliate, plate_number e label.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(cropped_folder, exist_ok=True)\n",
    "    cropped_rows = []\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        image_path = row[\"image_path\"]\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Immagine non trovata o corrotta: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            x1 = int(float(row[\"x1_bbox\"]))\n",
    "            y1 = int(float(row[\"y1_bbox\"]))\n",
    "            x2 = int(float(row[\"x2_bbox\"]))\n",
    "            y2 = int(float(row[\"y2_bbox\"]))\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nei bounding box per {image_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        resized_img = crop_and_resize(img, x1, y1, x2, y2)\n",
    "        if resized_img is None:\n",
    "            print(f\"Errore nel crop/resize dell'immagine: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        cropped_path = os.path.join(cropped_folder, f\"cropped_{i}.jpg\")\n",
    "        cv2.imwrite(cropped_path, resized_img)\n",
    "\n",
    "        cropped_rows.append({\n",
    "            \"image_path\": cropped_path,\n",
    "            \"plate_number\": row[\"plate_number\"],\n",
    "            \"label\": row[\"label\"]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(cropped_rows)\n",
    "\n",
    "def plot_batch_images(train_loader, idx2char, font=prop):\n",
    "    images, labels = next(iter(train_loader))\n",
    "    \n",
    "    # Seleziona 20 indici casuali dal batch\n",
    "    indices = np.random.choice(len(images), size=25, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(20, 10))  \n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, idx in zip(axes, indices):\n",
    "        image = images[idx]\n",
    "        label = labels[idx]\n",
    "\n",
    "        decoded_plate = decode_plate_from_list([int(i) for i in label], idx2char)\n",
    "        img_np = to_pil_image(image)\n",
    "\n",
    "        ax.imshow(img_np)\n",
    "        ax.set_title(f\"Plate: {decoded_plate}\", fontproperties=font, fontsize=18)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:36:05.444458Z",
     "iopub.status.busy": "2025-07-14T15:36:05.444211Z",
     "iopub.status.idle": "2025-07-14T15:36:05.468226Z",
     "shell.execute_reply": "2025-07-14T15:36:05.467600Z",
     "shell.execute_reply.started": "2025-07-14T15:36:05.444431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def infer_and_evaluate(model, image_tensor, target_indices, char2idx, idx2char, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Assumiamo batch_size = 1\n",
    "    images = image_tensor.unsqueeze(0).to(device)       # (1, C, H, W)\n",
    "    targets = [target_indices.to(device)]               # list of tensors\n",
    "    target_lengths = torch.tensor([len(t) for t in targets], dtype=torch.long, device=device)\n",
    "    targets_concat = torch.cat(targets)                 # flatten targets\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(images)                              # (1, T, C)\n",
    "\n",
    "    # Decoding (greedy)\n",
    "    blank_idx = char2idx['-']\n",
    "    decoded = greedy_decode(logits, blank_idx, idx2char)\n",
    "\n",
    "    # Prepare input for CTC loss\n",
    "    log_probs = F.log_softmax(logits, dim=2).permute(1, 0, 2)  # (T, N, C)\n",
    "    input_lengths = torch.full(size=(1,), fill_value=log_probs.size(0), dtype=torch.long).to(device)\n",
    "\n",
    "    # CTC Loss\n",
    "    ctc_loss_fn = nn.CTCLoss(blank=blank_idx, zero_infinity=True)\n",
    "    loss = ctc_loss_fn(log_probs, targets_concat, input_lengths, target_lengths)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Predetta: {decoded[0]}\")\n",
    "    print(f\"Target:   {decode_plate_from_list(target_indices.tolist(), idx2char)}\")\n",
    "    print(f\"CTC Loss: {loss.item():.4f}\")\n",
    "    print(f\"Len pred: {len(decoded[0])}, Len true: {target_lengths.item()}\")\n",
    "\n",
    "    return decoded[0], loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:36:05.469982Z",
     "iopub.status.busy": "2025-07-14T15:36:05.469783Z",
     "iopub.status.idle": "2025-07-14T15:36:48.690815Z",
     "shell.execute_reply": "2025-07-14T15:36:48.689817Z",
     "shell.execute_reply.started": "2025-07-14T15:36:05.469967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_id = '1RGEnfa5xWhDzO6oSoECQwQwyP4BRH5d_'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "download_and_extract_dataset(url, output_path, extract_path, folder_path)\n",
    "\n",
    "if working_on_kaggle:\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:36:48.692163Z",
     "iopub.status.busy": "2025-07-14T15:36:48.691863Z",
     "iopub.status.idle": "2025-07-14T15:36:49.501333Z",
     "shell.execute_reply": "2025-07-14T15:36:49.500737Z",
     "shell.execute_reply.started": "2025-07-14T15:36:48.692139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = create_dataframe(folder_path, char2idx)\n",
    "\n",
    "df = df[:NUM_SAMPLES] #TODO: ricordiamo di togliere questo\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop and resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:36:49.502701Z",
     "iopub.status.busy": "2025-07-14T15:36:49.502127Z",
     "iopub.status.idle": "2025-07-14T15:39:36.269915Z",
     "shell.execute_reply": "2025-07-14T15:39:36.269304Z",
     "shell.execute_reply.started": "2025-07-14T15:36:49.502674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame with the cropped images\n",
    "if os.path.isdir(cropped_folder):\n",
    "    num_files = len([f for f in os.listdir(cropped_folder) if os.path.isfile(os.path.join(cropped_folder, f))])\n",
    "    print(f\"Found {num_files} files in '{cropped_folder}' (expected: {NUM_SAMPLES})\")\n",
    "\n",
    "    if num_files == NUM_SAMPLES:\n",
    "        print(\"Cropped folder already processed. Skipping cropping step.\")\n",
    "    else:\n",
    "        print(\"Cropped folder incomplete. Reprocessing...\")\n",
    "        cropped_df = create_cropped_dataframe(df, cropped_folder)\n",
    "else:\n",
    "    print(f\"The folder '{cropped_folder}' doesn't exist. Creating and processing...\")\n",
    "    os.makedirs(cropped_folder, exist_ok=True)\n",
    "    cropped_df = create_cropped_dataframe(df, cropped_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.270897Z",
     "iopub.status.busy": "2025-07-14T15:39:36.270653Z",
     "iopub.status.idle": "2025-07-14T15:39:36.670440Z",
     "shell.execute_reply": "2025-07-14T15:39:36.669795Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.270873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Choose a sample in the dataset\n",
    "i = np.random.randint(0, len(df))\n",
    "img = cv2.imread(df.iloc[i][\"image_path\"])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converti in RGB per matplotlib\n",
    "\n",
    "# Draw the bounding box\n",
    "x1, y1 = int(df.iloc[i][\"x1_bbox\"]), int(df.iloc[i][\"y1_bbox\"])\n",
    "x2, y2 = int(df.iloc[i][\"x2_bbox\"]), int(df.iloc[i][\"y2_bbox\"])\n",
    "cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "\n",
    "# Aggiungi la targa decodificata sull’immagine (con OpenCV)\n",
    "plate_text = df.iloc[i]['plate_number']\n",
    "\n",
    "# Mostra l'immagine con titolo che usa il font CJK di matplotlib\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Plate: {plate_text}\", fontproperties=prop)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "img = cv2.imread(cropped_df.iloc[i][\"image_path\"])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Plate: {plate_text}\", fontproperties=prop)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.671281Z",
     "iopub.status.busy": "2025-07-14T15:39:36.671094Z",
     "iopub.status.idle": "2025-07-14T15:39:36.676148Z",
     "shell.execute_reply": "2025-07-14T15:39:36.675538Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.671267Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset personalizzato\n",
    "class PlateDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = row[\"label\"]  # list\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.677272Z",
     "iopub.status.busy": "2025-07-14T15:39:36.677100Z",
     "iopub.status.idle": "2025-07-14T15:39:36.693654Z",
     "shell.execute_reply": "2025-07-14T15:39:36.692922Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.677259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To handle with CCPD-DB: Illuminations on the LP area are dark, uneven or extremely bright.\n",
    "# Simulate night\n",
    "transform_night = transforms.Compose([\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.1, 0.3), angle_range=(-20, 20), beam_width_range=(10, 60), beam_type = \"black\")],\n",
    "                            p=0.6),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.1, 0.3), angle_range=(-20, 20), beam_width_range=(10, 60), beam_type = \"black\")],\n",
    "                            p=0.6),\n",
    "\n",
    "    AddNoise(noise_level=(0.005, 0.05), p=0.6),\n",
    "    RandomGaussianBlur(radius=(0.1, 1), p=0.7),\n",
    "    RandomMotionBlur(kernel_size=(5, 7), p=0.7),\n",
    "\n",
    "    BluePlateHighlight(intensity_range=(1, 1.6), p=0.75),\n",
    "    MatrixEffect(intensity=(0.7, 0.9), p=0.85),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(  \n",
    "            brightness=(0.4, 0.7),     \n",
    "            contrast=(1, 2.5),       \n",
    "            )], p=0.60),\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(       \n",
    "            saturation=(0.5, 1),     \n",
    "            )], p=0.60),\n",
    "   \n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(   \n",
    "            brightness=(0.4, 0.7),     \n",
    "            contrast=(1, 2),       \n",
    "            )], p=0.60),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(     \n",
    "            # contrast=(1, 2),       \n",
    "            saturation=(0.4, 1),     \n",
    "            )], p=0.60),\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.20, p=0.20),\n",
    "    SimulateDistance(scale_range=(0.5, 0.7), p=0.95), \n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.4\n",
    "    ),            \n",
    "    \n",
    "    transforms.CenterCrop((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Simulate brightness\n",
    "transform_day = transforms.Compose([\n",
    "    RandomMotionBlur(kernel_size=(5, 7), p=0.30),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(   # For \"db\" and \"challenge\" datasets\n",
    "            brightness=(1.2, 2),     \n",
    "            contrast=(1, 1.5),       \n",
    "            saturation=(0.6, 1.4),     \n",
    "            hue=(-0.05, 0.05)),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    AddNoise(noise_level=(0.001, 0.01), p=0.2),\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.5, 0.9), angle_range=(-20, 20), beam_width_range=(20, 80), beam_type = \"white\")],\n",
    "                            p=0.4),\n",
    "    AddFog(fog_factor=(0.2, 0.7), p=0.2),\n",
    "    \n",
    "    transforms.RandomPerspective(distortion_scale=0.20, p=0.20),\n",
    "    SimulateDistance(scale_range=(0.5, 0.7), p=0.95), \n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.4\n",
    "    ),\n",
    "    transforms.CenterCrop((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.695971Z",
     "iopub.status.busy": "2025-07-14T15:39:36.695775Z",
     "iopub.status.idle": "2025-07-14T15:39:36.716538Z",
     "shell.execute_reply": "2025-07-14T15:39:36.715882Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.695956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To handle CPD-FN: The distance from the LP to the shooting location is relatively far or near.\n",
    "transform_fn = transforms.Compose([\n",
    "    # Trasformazione 5\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.2, 0.4), angle_range=(-20, 20), beam_width_range=(10, 40), beam_type = \"black\")],\n",
    "                            p=0.4),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.2, 0.4), angle_range=(-20, 20), beam_width_range=(10, 40), beam_type = \"white\")],\n",
    "                            p=0.4),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(   # For \"db\" and \"challenge\" datasets\n",
    "             brightness=(0.6, 1.0),     \n",
    "            contrast=(0.8, 1.2),       \n",
    "            saturation=(0.4, .8),     \n",
    "            hue=(-0.05, 0.05)),\n",
    "    ], p=0.8),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            # scale=(0.9, 1.1),\n",
    "            degrees=(-10, 10),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-15, 15, -10, -10),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.99),\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.20),\n",
    "    AddNoise(noise_level=(0.005, 0.1), p=0.6),\n",
    "    RandomMotionBlur(kernel_size=(7, 9), p=0.6),\n",
    "    RandomGaussianBlur(radius=(0.5, 2), p=0.6),                       \n",
    "    SimulateDistance(scale_range=(0.25, 0.45), p=0.6),\n",
    "\n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.5\n",
    "    ),\n",
    "    transforms.CenterCrop((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.717483Z",
     "iopub.status.busy": "2025-07-14T15:39:36.717228Z",
     "iopub.status.idle": "2025-07-14T15:39:36.740510Z",
     "shell.execute_reply": "2025-07-14T15:39:36.739774Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.717452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To handle with CCPD-Blur: Blurry largely due to hand jitter while taking pictures.\n",
    "transform_blur = transforms.Compose([\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(   # For \"db\" and \"challenge\" datasets\n",
    "            brightness=(0.6, 1.4),     \n",
    "            contrast=(0.6, 1.4),       \n",
    "            saturation=(0.6, 1.4),     \n",
    "            hue=(-0.05, 0.05)),\n",
    "    ], p=0.8),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            scale=(0.9, 1),\n",
    "            degrees=(-5, 5),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-5, 5, -5, 5),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.6),\n",
    "\n",
    "    RandomMotionBlur(kernel_size=(7, 10), p=0.40),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.40),\n",
    "    SimulateDistance(scale_range=(0.7, 0.9), p=0.20),\n",
    "\n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.65\n",
    "    ),\n",
    "    transforms.CenterCrop((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.741611Z",
     "iopub.status.busy": "2025-07-14T15:39:36.741328Z",
     "iopub.status.idle": "2025-07-14T15:39:36.761920Z",
     "shell.execute_reply": "2025-07-14T15:39:36.761271Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.741589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CCPD-Rotate Great horizontal tilt degree (20◦ - 50◦) and the vertical tilt degree varies from -10◦ to 10◦.\n",
    "transform_rot_1 = transforms.Compose([\n",
    "    transforms.RandomApply([RandomColorPad(pad_y_range=(15, 20), pad_x_range=(15, 20), color_pad='random')], p=0.99),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.6, 1.4),     \n",
    "            contrast=(0.6, 1.4),       \n",
    "            saturation=(0.6, 1.4),     \n",
    "            hue=(-0.08, 0.08)),\n",
    "    ], p=0.90),\n",
    "    \n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            scale=(0.7, 0.9),\n",
    "            degrees=(-20, -15),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-10, 10, -10, 10),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.95),\n",
    "\n",
    "    AddNoise(noise_level=(0.005, 0.1), p=0.4),\n",
    "    RandomGaussianBlur(radius=(0.1, 0.5), p=0.4),    \n",
    "    RandomMotionBlur(kernel_size=(5, 7), p=0.4),\n",
    "    SimulateDistance(scale_range=(0.6, 0.9), p=0.30),\n",
    "    # transforms.RandomPerspective(distortion_scale=0.4, p=0.30),\n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.5\n",
    "    ),\n",
    "    transforms.CenterCrop((60, 180)),\n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.CenterCrop((48, 90)),\n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_rot_2 = transforms.Compose([\n",
    "    transforms.RandomApply([RandomColorPad(pad_y_range=(15, 20), pad_x_range=(15, 20), color_pad='random')], p=0.99),\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.6, 1.4),     \n",
    "            contrast=(0.6, 1.4),       \n",
    "            saturation=(0.6, 1.4),     \n",
    "            hue=(-0.08, 0.08)),\n",
    "    ], p=0.90),\n",
    "    \n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            scale=(0.7, 0.9),\n",
    "            degrees=(15, 20),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-10, 10, -10, 10),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.95),\n",
    "\n",
    "    AddNoise(noise_level=(0.005, 0.1), p=0.4),\n",
    "    RandomGaussianBlur(radius=(0.1, 0.5), p=0.4),    \n",
    "    RandomMotionBlur(kernel_size=(5, 7), p=0.4),\n",
    "    SimulateDistance(scale_range=(0.6, 0.9), p=0.30),\n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.5\n",
    "    ),\n",
    "    # transforms.RandomPerspective(distortion_scale=0.4, p=0.30),\n",
    "    transforms.CenterCrop((60, 180)),\n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.CenterCrop((48, 90)),\n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate tilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.762795Z",
     "iopub.status.busy": "2025-07-14T15:39:36.762567Z",
     "iopub.status.idle": "2025-07-14T15:39:36.783725Z",
     "shell.execute_reply": "2025-07-14T15:39:36.782915Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.762772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# To handle with CCPD-Tilt Great horizontal tilt degree and vertical tilt degree.\n",
    "transform_tilt_1 = transforms.Compose([\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.7, 1.3),     \n",
    "            contrast=(0.7, 1.3),       \n",
    "            saturation=(0.7, 1.3),     \n",
    "            hue=(-0.08, 0.08)),\n",
    "    ], p=0.5),\n",
    "\n",
    "    transforms.RandomApply([RandomColorPad(pad_y_range=(10, 40), pad_x_range=(15, 25), color_pad='random')], p=0.99),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            # scale=(0.9, 1.1),\n",
    "            degrees=(-0, 0),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-25, 25, -18, -5),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.99),\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.20, p=0.70),\n",
    "    \n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.CenterCrop((40, 100)),\n",
    "    transforms.Resize((48, 144)),\n",
    "\n",
    "    RandomGaussianBlur(radius=(0.05, 0.15), p=0.20),\n",
    "    RandomMotionBlur(kernel_size=(5, 7), p=0.3),\n",
    "    SimulateDistance(scale_range=(0.8, 1), p=0.3),\n",
    "\n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.6\n",
    "    ),\n",
    "\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_tilt_2 = transforms.Compose([\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.7, 1.3),     \n",
    "            contrast=(0.7, 1.3),       \n",
    "            saturation=(0.7, 1.3),     \n",
    "            hue=(-0.08, 0.08)),\n",
    "    ], p=0.5),\n",
    "\n",
    "    transforms.RandomApply([RandomColorPad(pad_y_range=(10, 40), pad_x_range=(15, 25), color_pad='random')], p=0.99),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            # scale=(0.9, 1.1),\n",
    "            degrees=(-0, 0),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-25, 25, 5, 18),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.99),\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.20, p=0.70),\n",
    "    \n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.CenterCrop((40, 100)),\n",
    "    transforms.Resize((48, 144)),\n",
    "\n",
    "    RandomGaussianBlur(radius=(0.05, 0.15), p=0.20),\n",
    "    RandomMotionBlur(kernel_size=(5, 7), p=0.3),\n",
    "    SimulateDistance(scale_range=(0.8, 1), p=0.3),\n",
    "\n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.6\n",
    "    ),\n",
    "\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.785023Z",
     "iopub.status.busy": "2025-07-14T15:39:36.784525Z",
     "iopub.status.idle": "2025-07-14T15:39:36.805872Z",
     "shell.execute_reply": "2025-07-14T15:39:36.805165Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.785005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To handle with CCPD-Challenge: The most challenging images for LPDR to date.\n",
    "transform_challenge = transforms.Compose([\n",
    "     transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.2, 0.6), angle_range=(-20, 20), beam_width_range=(20, 50), beam_type = \"black\")],\n",
    "                            p=0.4),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "    RandomLightBeam(intensity=(0.2, 0.6), angle_range=(-20, 20), beam_width_range=(20, 50), beam_type = \"white\")],\n",
    "                            p=0.4),\n",
    "\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(\n",
    "            brightness=(0.5, 1.5),     \n",
    "            contrast=(0.5, 1.5),       \n",
    "            saturation=(0.5, 1.5),     \n",
    "            hue=(-0.08, 0.08)),\n",
    "    ], p=0.70),\n",
    "    \n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomAffine(\n",
    "            scale=(0.9, 1),\n",
    "            degrees=(-10, 10),              # to simulate \"rotate\", \"tilt\". \"challenge\"\n",
    "            # translate=(0.10, 0.10),\n",
    "            shear=(-10, 10, -10, 10),                \n",
    "            fill=0\n",
    "        )\n",
    "    ], p=0.6),\n",
    "\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.40),\n",
    "    AddNoise(noise_level=(0.005, 0.05), p=0.4),\n",
    "    RandomMotionBlur(kernel_size=(7, 9), p=0.4),\n",
    "    RandomGaussianBlur(radius=(0.5, 1), p=0.4),                    \n",
    "    SimulateDistance(scale_range=(0.7, 0.9), p=0.40),\n",
    "    MatrixEffect(intensity=(0.8, 1), p=0.1),\n",
    "\n",
    "    BlockShiftTransform(\n",
    "        direction='both',\n",
    "        num_blocks_range_horizontal=(4, 10),\n",
    "        num_blocks_range_vertical=(4, 16), \n",
    "        max_shift=1, \n",
    "        p=0.8\n",
    "    ),\n",
    "    \n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T15:39:36.806866Z",
     "iopub.status.busy": "2025-07-14T15:39:36.806611Z",
     "iopub.status.idle": "2025-07-14T15:39:39.714112Z",
     "shell.execute_reply": "2025-07-14T15:39:39.713385Z",
     "shell.execute_reply.started": "2025-07-14T15:39:36.806849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(cropped_df, test_size=VAL_SPLIT_SIZE, shuffle=True, random_state=SEED)\n",
    "dfs = np.array_split(train_df, 7)\n",
    "\n",
    "dataset_night = PlateDataset(dfs[0], transform=transform_night)\n",
    "dataset_day = PlateDataset(dfs[1], transform=transform_day)\n",
    "dataset_fn = PlateDataset(dfs[2], transform=transform_fn)\n",
    "dataset_blur = PlateDataset(dfs[3], transform=transform_blur)\n",
    "idx_tilt = int(0.5 * len(dfs[4]))\n",
    "dataset_tilt_1 = PlateDataset(dfs[4][:idx_tilt], transform=transform_tilt_1)\n",
    "dataset_tilt_2 = PlateDataset(dfs[4][idx_tilt:], transform=transform_tilt_2)\n",
    "idx_rot = int(0.5 * len(dfs[5]))\n",
    "dataset_rot_1 = PlateDataset(dfs[5][:idx_rot], transform=transform_rot_1)\n",
    "dataset_rot_2 = PlateDataset(dfs[5][:idx_rot], transform=transform_rot_2)\n",
    "dataset_challenge = PlateDataset(dfs[6], transform=transform_challenge)\n",
    "\n",
    "\n",
    "augmented_dataset = ConcatDataset([\n",
    "    dataset_night,\n",
    "    dataset_day,\n",
    "    dataset_fn,\n",
    "    dataset_blur,\n",
    "    dataset_tilt_1,\n",
    "    dataset_tilt_2,\n",
    "    dataset_rot_1,\n",
    "    dataset_rot_2,\n",
    "    dataset_challenge\n",
    " ])\n",
    "\n",
    "train_loader = DataLoader(augmented_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Solo normalizzazione (niente data augmentation) per validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((48, 144)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_dataset = PlateDataset(val_df, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "plot_batch_images(train_loader, idx2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T20:54:22.188281Z",
     "iopub.status.busy": "2025-07-14T20:54:22.187540Z",
     "iopub.status.idle": "2025-07-14T22:04:52.283239Z",
     "shell.execute_reply": "2025-07-14T22:04:52.282350Z",
     "shell.execute_reply.started": "2025-07-14T20:54:22.188228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = PDLPR(num_classes=num_classes)\n",
    "model = model.to(device)  # Sposto modello su cuda:0\n",
    "\n",
    "print(\"Start training...\")\n",
    "model, train_losses, val_losses = train(train_loader, val_loader, model, char2idx, device, num_epochs,\n",
    "      lr, load_checkpoint_path, save_checkpoint_path, lr_decay_factor, lr_decay_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:04:52.285426Z",
     "iopub.status.busy": "2025-07-14T22:04:52.285147Z",
     "iopub.status.idle": "2025-07-14T22:04:52.477764Z",
     "shell.execute_reply": "2025-07-14T22:04:52.477042Z",
     "shell.execute_reply.started": "2025-07-14T22:04:52.285396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Andamento della Loss durante il Training')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:04:52.478717Z",
     "iopub.status.busy": "2025-07-14T22:04:52.478525Z",
     "iopub.status.idle": "2025-07-14T22:04:52.487739Z",
     "shell.execute_reply": "2025-07-14T22:04:52.487161Z",
     "shell.execute_reply.started": "2025-07-14T22:04:52.478702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def infer_and_evaluate(model, image_tensor, target_indices, char2idx, idx2char, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    def char_accuracy(pred, target):\n",
    "        matches = sum(p == t for p, t in zip(pred, target))\n",
    "        return matches / max(len(target), 1)\n",
    "\n",
    "    def sequence_accuracy(pred, target):\n",
    "        return int(pred == target)\n",
    "\n",
    "    # Assumiamo batch_size = 1\n",
    "    images = image_tensor.unsqueeze(0).to(device)       # (1, C, H, W)\n",
    "    targets = [target_indices.to(device)]               # list of tensors\n",
    "    target_lengths = torch.tensor([len(t) for t in targets], dtype=torch.long, device=device)\n",
    "    targets_concat = torch.cat(targets)                 # flatten targets\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(images)                              # (1, T, C)\n",
    "    log_probs = F.log_softmax(logits, dim=2)            # (1, T, C)\n",
    "\n",
    "    # Get raw argmax predictions per timestep (including blanks)\n",
    "    raw_preds = torch.argmax(log_probs, dim=2)[0]       # (T,)\n",
    "    raw_seq = ''.join([idx2char[idx.item()] for idx in raw_preds])\n",
    "\n",
    "    # Decoding (greedy with collapsing + blank removal)\n",
    "    blank_idx = char2idx['-']\n",
    "    decoded = greedy_decode(logits, blank_idx, idx2char)  # lista di stringhe (batch 1)\n",
    "    target_str = decode_plate_from_list(target_indices.tolist(), idx2char)\n",
    "\n",
    "    # Accuracy metrics\n",
    "    c_acc = char_accuracy(decoded[0], target_str)\n",
    "    s_acc = sequence_accuracy(decoded[0], target_str)\n",
    "\n",
    "    # Prepare input for CTC loss\n",
    "    log_probs_ctc = log_probs.permute(1, 0, 2)           # (T, N, C)\n",
    "    input_lengths = torch.full(size=(1,), fill_value=log_probs_ctc.size(0), dtype=torch.long).to(device)\n",
    "\n",
    "    # CTC Loss\n",
    "    ctc_loss_fn = nn.CTCLoss(blank=blank_idx, zero_infinity=True)\n",
    "    loss = ctc_loss_fn(log_probs_ctc, targets_concat, input_lengths, target_lengths)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Raw sequence (argmax per timestep): {raw_seq}\")\n",
    "    print(f\"Predetta:          {decoded[0]}\")\n",
    "    print(f\"Target:            {target_str}\")\n",
    "    print(f\"CTC Loss:          {loss.item():.4f}\")\n",
    "    print(f\"Len pred:          {len(decoded[0])}, Len true: {target_lengths.item()}\")\n",
    "    print(f\"Character Accuracy: {c_acc:.4f}\")\n",
    "    print(f\"Sequence Accuracy:  {s_acc}\")\n",
    "\n",
    "    return decoded[0], loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:04:52.489595Z",
     "iopub.status.busy": "2025-07-14T22:04:52.489394Z",
     "iopub.status.idle": "2025-07-14T22:04:52.813311Z",
     "shell.execute_reply": "2025-07-14T22:04:52.812465Z",
     "shell.execute_reply.started": "2025-07-14T22:04:52.489580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(val_loader))\n",
    "i = np.random.randint(0, len(images))\n",
    "print(i)\n",
    "\n",
    "# First image and label\n",
    "first_image = images[i]\n",
    "first_label = labels[i]\n",
    "\n",
    "\n",
    "decoded_str, loss_value = infer_and_evaluate(model, first_image, first_label, char2idx, idx2char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:19:51.107695Z",
     "iopub.status.busy": "2025-07-14T22:19:51.107450Z",
     "iopub.status.idle": "2025-07-14T22:19:54.198126Z",
     "shell.execute_reply": "2025-07-14T22:19:54.197169Z",
     "shell.execute_reply.started": "2025-07-14T22:19:51.107672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:04:52.814999Z",
     "iopub.status.busy": "2025-07-14T22:04:52.814736Z",
     "iopub.status.idle": "2025-07-14T22:05:44.557384Z",
     "shell.execute_reply": "2025-07-14T22:05:44.556598Z",
     "shell.execute_reply.started": "2025-07-14T22:04:52.814975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_output_path = 'dataset/ccpd_test.tar'\n",
    "test_extract_path = 'dataset'\n",
    "test_folder_path = os.path.join(test_extract_path, 'ccpd_test')  # cartella che sarà estratta\n",
    "test_cropped_folder = 'dataset/ccpd_test_cropped'\n",
    "\n",
    "# Adatta i percorsi se stai lavorando su Kaggle\n",
    "if working_on_kaggle:\n",
    "    test_output_path = '/kaggle/working/ccpd_test.tar'\n",
    "    test_extract_path = '/kaggle/working/dataset'\n",
    "    test_folder_path = os.path.join(test_extract_path, 'ccpd_test')\n",
    "    test_cropped_folder = '/kaggle/working/ccpd_test_cropped'\n",
    "\n",
    "# Crea cartelle se non esistono\n",
    "os.makedirs(os.path.dirname(test_output_path), exist_ok=True)\n",
    "os.makedirs(test_cropped_folder, exist_ok=True)\n",
    "\n",
    "# URL_TEST di download\n",
    "file_id_test = '1PnYtN0P6m36LmjztvhVmVLqZwZAp9Q3X'\n",
    "url_test = f'https://drive.google.com/uc?id={file_id_test}'\n",
    "\n",
    "download_and_extract_dataset(url_test, test_output_path, test_extract_path, test_folder_path)\n",
    "\n",
    "if os.path.exists(test_folder_path):\n",
    "    subfolders = [name for name in os.listdir(test_folder_path)\n",
    "                  if os.path.isdir(os.path.join(test_folder_path, name))]\n",
    "    subfolders = sorted(subfolders)\n",
    "    print(f\"Subfolders in '{test_folder_path}':\")\n",
    "else:\n",
    "    print(f\"The folder '{test_folder_path}' does not exist.\")\n",
    "\n",
    "# # TODO: se la cartella \n",
    "for subfolder in subfolders:\n",
    "    print(f\"\\nEvaluation on CCPD_{subfolder}\")\n",
    "    subfolder_path = os.path.join(test_folder_path, subfolder) \n",
    "    \n",
    "    sub_df = create_dataframe(subfolder_path, char2idx)\n",
    "\n",
    "    cropped_subfolder =  os.path.join(test_cropped_folder, subfolder)\n",
    "    os.makedirs(cropped_subfolder, exist_ok=True)\n",
    "    cropped_sub_df = create_cropped_dataframe(sub_df, cropped_subfolder)\n",
    "\n",
    "    test_dataset = PlateDataset(cropped_sub_df, transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    test_loss, test_char_acc, test_seq_acc = evaluate_model(model, test_loader, char2idx, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:05:44.558768Z",
     "iopub.status.busy": "2025-07-14T22:05:44.558517Z",
     "iopub.status.idle": "2025-07-14T22:05:51.017490Z",
     "shell.execute_reply": "2025-07-14T22:05:51.016745Z",
     "shell.execute_reply.started": "2025-07-14T22:05:44.558745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for subfolder in subfolders:\n",
    "    if subfolder == \"tilt\":\n",
    "        print(f\"\\nEvaluation on CCPD_{subfolder}\")\n",
    "        subfolder_path = os.path.join(test_folder_path, subfolder) \n",
    "        \n",
    "        sub_df = create_dataframe(subfolder_path, char2idx)\n",
    "    \n",
    "        cropped_subfolder =  os.path.join(test_cropped_folder, subfolder)\n",
    "        os.makedirs(cropped_subfolder, exist_ok=True)\n",
    "        cropped_sub_df = create_cropped_dataframe(sub_df, cropped_subfolder)\n",
    "    \n",
    "        test_dataset = PlateDataset(cropped_sub_df, transform=val_transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        \n",
    "        test_loss, test_char_acc, test_seq_acc = evaluate_model(model, test_loader, char2idx, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:16:02.776843Z",
     "iopub.status.busy": "2025-07-14T22:16:02.776088Z",
     "iopub.status.idle": "2025-07-14T22:16:02.982038Z",
     "shell.execute_reply": "2025-07-14T22:16:02.981159Z",
     "shell.execute_reply.started": "2025-07-14T22:16:02.776805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_loader))\n",
    "i = np.random.randint(0, len(images))\n",
    "print(i)\n",
    "\n",
    "# Estrai immagine e label\n",
    "first_image = images[i]\n",
    "first_label = labels[i]\n",
    "\n",
    "# Mostra l'immagine\n",
    "plt.figure(figsize=(10, 2))\n",
    "# Se l'immagine ha una sola canale (grayscale), squeeze per renderla 2D\n",
    "if first_image.shape[0] == 1:\n",
    "    plt.imshow(first_image.squeeze(0).cpu().numpy(), cmap='gray')\n",
    "else:\n",
    "    plt.imshow(np.transpose(first_image.cpu().numpy(), (1, 2, 0)))  # per RGB\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "decoded_str, loss_value = infer_and_evaluate(model, first_image, first_label, char2idx, idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:05:51.192377Z",
     "iopub.status.busy": "2025-07-14T22:05:51.192152Z",
     "iopub.status.idle": "2025-07-14T22:05:54.510118Z",
     "shell.execute_reply": "2025-07-14T22:05:54.509426Z",
     "shell.execute_reply.started": "2025-07-14T22:05:51.192342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"List of subfolders: \", subfolders)\n",
    "subfolder = 'tilt'\n",
    "subfolder_path = subfolder_path = os.path.join(test_folder_path, subfolder)\n",
    "sub_df = create_dataframe(subfolder_path, char2idx)\n",
    "cropped_subfolder =  os.path.join(test_cropped_folder, subfolder)\n",
    "print(cropped_subfolder)\n",
    "os.makedirs(cropped_subfolder, exist_ok=True)\n",
    "\n",
    "cropped_sub_df = create_cropped_dataframe(sub_df, cropped_subfolder)\n",
    "\n",
    "test_dataset = PlateDataset(cropped_sub_df, transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T22:05:54.511168Z",
     "iopub.status.busy": "2025-07-14T22:05:54.510979Z",
     "iopub.status.idle": "2025-07-14T22:05:56.461136Z",
     "shell.execute_reply": "2025-07-14T22:05:56.460136Z",
     "shell.execute_reply.started": "2025-07-14T22:05:54.511146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_batch_images(test_loader, idx2char)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7846535,
     "sourceId": 12439120,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
