{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import**","metadata":{}},{"cell_type":"code","source":"import tarfile\nimport shutil\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport yaml\nimport os, torch\nfrom pathlib import Path\nfrom torchvision.ops import box_iou\nimport warnings\nimport sys, time, warnings, subprocess\nfrom kaggle_secrets import UserSecretsClient\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:01:08.781167Z","iopub.execute_input":"2025-07-20T13:01:08.781436Z","iopub.status.idle":"2025-07-20T13:01:18.085365Z","shell.execute_reply.started":"2025-07-20T13:01:08.781410Z","shell.execute_reply":"2025-07-20T13:01:18.084600Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# **Globals**","metadata":{}},{"cell_type":"code","source":"# define the alphabet used for plate decoding. each LP number is comprised of a Chinese character, a letter, and five letters or numbers.\n\nPROVINCES = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\",\n             \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\",\n             \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\",\n             \"新\", \"警\", \"学\", \"O\"]\n\nALPHA = ['A','B','C','D','E','F','G','H','J','K',\n             'L','M','N','P','Q','R','S','T','U','V',\n             'W','X','Y','Z','O'] \n\nADS = ['A','B','C','D','E','F','G','H','J','K',\n       'L','M','N','P','Q','R','S','T','U','V',\n       'W','X','Y','Z','0','1','2','3','4','5',\n       '6','7','8','9','O']\n\nSRC_IMG_DIR = \"/kaggle/working/ccpd_subset_base/train\"\nOUT_BASE = \"/kaggle/working/ccpd_yolo_dataset\"\nIMG_W, IMG_H = 720, 1160\nCLASS_ID = 0\n\n# specify the path for train & val for yolov5\nCONTENT = {\n    'train': '/kaggle/working/ccpd_yolo_dataset/images/train',\n    'val': '/kaggle/working/ccpd_yolo_dataset/images/val',\n    'nc': 1,\n    'names': ['plate']\n}\n\nCCPD_PATH = \"yolov5/ccpd.yaml\"   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:01:45.075268Z","iopub.execute_input":"2025-07-20T13:01:45.075693Z","iopub.status.idle":"2025-07-20T13:01:45.081506Z","shell.execute_reply.started":"2025-07-20T13:01:45.075668Z","shell.execute_reply":"2025-07-20T13:01:45.080849Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# **Utils**","metadata":{}},{"cell_type":"code","source":"#cloning the yolov5 repo.\n!git clone https://github.com/ultralytics/yolov5  \n%cd yolov5\n%pip install -qr requirements.txt  #dependencies\n%cd ..","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:03:01.215287Z","iopub.execute_input":"2025-07-20T13:03:01.215599Z","iopub.status.idle":"2025-07-20T13:04:21.233651Z","shell.execute_reply.started":"2025-07-20T13:03:01.215567Z","shell.execute_reply":"2025-07-20T13:04:21.232733Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 17516, done.\u001b[K\nremote: Counting objects: 100% (19/19), done.\u001b[K\nremote: Compressing objects: 100% (19/19), done.\u001b[K\nremote: Total 17516 (delta 6), reused 0 (delta 0), pack-reused 17497 (from 4)\u001b[K\nReceiving objects: 100% (17516/17516), 16.61 MiB | 32.64 MiB/s, done.\nResolving deltas: 100% (11994/11994), done.\n/kaggle/working/yolov5\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n/kaggle/working\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"os.makedirs(os.path.dirname(CCPD_PATH), exist_ok=True)\n\n#write the .yaml file in /kaggle/working/yolov5/ccpd.yaml\nwith open(CCPD_PATH, 'w') as f:\n    yaml.dump(CONTENT, f, sort_keys=False)\n\nprint(f\"file added in: {os.getcwd()}/{CCPD_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:04:48.182977Z","iopub.execute_input":"2025-07-20T13:04:48.183290Z","iopub.status.idle":"2025-07-20T13:04:48.189828Z","shell.execute_reply.started":"2025-07-20T13:04:48.183261Z","shell.execute_reply":"2025-07-20T13:04:48.189132Z"}},"outputs":[{"name":"stdout","text":"file added in: /kaggle/working/yolov5/ccpd.yaml\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#extracting the metadata from each img in this format (image_path,x1_bbox,y1_bbox,x2_bbox,y2_bbox,plate_number)\ndef decode_plate(s):\n    \"this method is used for decoding the plate starting from the name of .jpg file\"\n    idx   = list(map(int, s.split(\"_\")))\n    try:\n        return PROVINCES[idx[0]] + ALPHA[idx[1]] + \"\".join(ADS[i] for i in idx[2:])\n    except Exception:\n        return None\n\n\ndef split_bbox(bbox_str):\n    \"extracting x1,y1,x2,y2, ex. '283___502_511___591'  →  ['283','502','511','591']\"\n    tokens = []\n    for seg in bbox_str.split(\"___\"):\n        tokens.extend(seg.split(\"_\"))\n    if len(tokens) == 4 and all(t.isdigit() for t in tokens):\n        return map(int, tokens)\n    return (None,)*4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:32:24.103850Z","iopub.execute_input":"2025-07-20T13:32:24.104091Z","iopub.status.idle":"2025-07-20T13:32:24.109720Z","shell.execute_reply.started":"2025-07-20T13:32:24.104073Z","shell.execute_reply":"2025-07-20T13:32:24.108957Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def export_yolo(df_split, split_name, img_w, img_h):\n    \"\"\"\n    This method is used for creating the dataset for yolov5.\n    Input: df_split (dataframe created by preovious method), split_name (train, val or test)\n    For each img we need to create .txt file, which contains:\n    CLASS_ID, x_center (normalized), y_center (normalized), width, height.\n    The file is created on the directory \"/kaggle/working/ccpd_yolo_dataset\" (OUT_BASE) \n    \"\"\"\n    img_dir = os.path.join(OUT_BASE, \"images\", split_name)\n    lbl_dir = os.path.join(OUT_BASE, \"labels\", split_name)\n    os.makedirs(img_dir, exist_ok=True)\n    os.makedirs(lbl_dir, exist_ok=True)\n\n    for _, row in df_split.iterrows():\n        try:\n            x_center = (row[\"x1_bbox\"] + row[\"x2_bbox\"]) / 2 / img_w\n            y_center = (row[\"y1_bbox\"] + row[\"y2_bbox\"]) / 2 / img_h\n            width = (row[\"x2_bbox\"] - row[\"x1_bbox\"]) / img_w\n            height = (row[\"y2_bbox\"] - row[\"y1_bbox\"]) / img_h\n\n            yolo_line = f\"{CLASS_ID} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n\n            base_name = os.path.basename(row[\"image_path\"])\n            name_no_ext = os.path.splitext(base_name)[0]\n\n            dst_img_path = os.path.join(img_dir, base_name)\n            shutil.copy2(row[\"image_path\"], dst_img_path)\n\n            #label YOLO\n            label_path = os.path.join(lbl_dir, f\"{name_no_ext}.txt\")\n            with open(label_path, \"w\") as f:\n                f.write(yolo_line)\n\n        except Exception as e:\n            print(f\"Error {row['image_path']}: {e}\")\n\n    print(f\"{split_name.upper()} completed  {len(df_split)} examples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:32:25.745690Z","iopub.execute_input":"2025-07-20T13:32:25.746195Z","iopub.status.idle":"2025-07-20T13:32:25.754664Z","shell.execute_reply.started":"2025-07-20T13:32:25.746174Z","shell.execute_reply":"2025-07-20T13:32:25.753796Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## **Data**","metadata":{}},{"cell_type":"code","source":"#download the training datatset, and test dataset (dim(train) = 50k, dim(test) = 8k).\n!gdown --folder https://drive.google.com/drive/folders/1YjnqKF3GV8BL-3ab88d5rzlx-skNSmxy -O datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:01:48.904184Z","iopub.execute_input":"2025-07-20T13:01:48.904465Z","iopub.status.idle":"2025-07-20T13:02:33.321758Z","shell.execute_reply.started":"2025-07-20T13:01:48.904444Z","shell.execute_reply":"2025-07-20T13:02:33.320815Z"}},"outputs":[{"name":"stdout","text":"Retrieving folder contents\nProcessing file 1At2itl6TyCoflqlgmAaAvy2J7r6LlxLi ccpd_test.tar\nProcessing file 14s-xOvv20PXJL_PxujiUogxLw57UjEul ccpd_train.tar\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1At2itl6TyCoflqlgmAaAvy2J7r6LlxLi\nFrom (redirected): https://drive.google.com/uc?id=1At2itl6TyCoflqlgmAaAvy2J7r6LlxLi&confirm=t&uuid=347f8bb6-d2d0-4cb5-b72d-f79d1ecb0017\nTo: /kaggle/working/datasets/ccpd_test.tar\n100%|█████████████████████████████████████████| 557M/557M [00:02<00:00, 192MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=14s-xOvv20PXJL_PxujiUogxLw57UjEul\nFrom (redirected): https://drive.google.com/uc?id=14s-xOvv20PXJL_PxujiUogxLw57UjEul&confirm=t&uuid=de577b69-6cac-4708-9ebf-4362db68e874\nTo: /kaggle/working/datasets/ccpd_train.tar\n100%|███████████████████████████████████████| 3.76G/3.76G [00:36<00:00, 103MB/s]\nDownload completed\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# extracting the .tar archive.\ndef extract_tar_archive(archive_path, destination_path):\n\n    print(f\"Extracting the tar archive in:{archive_path}\")\n    with tarfile.open(archive_path, \"r\") as tar:\n        tar.extractall(path=destination_path)\n        \n    print(f\"Archive extracted in: {destination_path}\")\n\n#delete the .tar archive which now is useless.\ndef delete_tar_archive(path_tar_archive):\n    \n    if os.path.exists(path_tar_archive):\n        shutil.rmtree(path_tar_archive)\n        print(f\"Folder eliminated: {path_tar_archive}\")\n    else:\n        print(f\"Folder not found: {path_tar_archive}\")\n        \narchive_path_train = \"/kaggle/working/datasets/ccpd_train.tar\"\narchive_path_test = \"/kaggle/working/datasets/ccpd_test.tar\"\nextract_path = \"/kaggle/working/\"\nfolder_path = \"/kaggle/working/ccpd_subset_base/train\"\n\n#when extracting the files, is important to eliminate the .tar archive which now occupy /kaggle/working space.\nextract_tar_archive(archive_path_train, extract_path)\nextract_tar_archive(archive_path_test, extract_path)\ndelete_tar_archive(\"/kaggle/working/datasets/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:02:41.216519Z","iopub.execute_input":"2025-07-20T13:02:41.217364Z","iopub.status.idle":"2025-07-20T13:02:57.154606Z","shell.execute_reply.started":"2025-07-20T13:02:41.217331Z","shell.execute_reply":"2025-07-20T13:02:57.153393Z"}},"outputs":[{"name":"stdout","text":"Extracting the tar archive in:/kaggle/working/datasets/ccpd_train.tar\nArchive extracted in: /kaggle/working/\nExtracting the tar archive in:/kaggle/working/datasets/ccpd_test.tar\nArchive extracted in: /kaggle/working/\nFolder eliminated: /kaggle/working/datasets/\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"folder = \"/kaggle/working/ccpd_subset_base/train\"\nrows   = []\n\nfor fname in os.listdir(folder):\n    if not fname.endswith(\".jpg\"): continue\n\n    parts = fname[:-4].split(\"-\")           \n    if len(parts) < 6:\n        continue #the ccpd file name is wrong           \n\n    x1,y1,x2,y2 = split_bbox(parts[2])      \n    plate = decode_plate(parts[4])    \n\n    rows.append({\n        \"image_path\": os.path.join(folder, fname),\n        \"x1_bbox\": x1, \"y1_bbox\": y1,\n        \"x2_bbox\": x2, \"y2_bbox\": y2,\n        \"plate_number\": plate\n    })\n\ndf = pd.DataFrame(rows)\nprint(\"Rows number:\", len(df))         \nprint(\"Columns numner:\", df.shape[1])\nprint(\"Shape:\", df.shape)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:32:29.880077Z","iopub.execute_input":"2025-07-20T13:32:29.880695Z","iopub.status.idle":"2025-07-20T13:32:30.300907Z","shell.execute_reply.started":"2025-07-20T13:32:29.880669Z","shell.execute_reply":"2025-07-20T13:32:30.300104Z"}},"outputs":[{"name":"stdout","text":"Rows number: 50000\nColumns numner: 6\nShape: (50000, 6)\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                          image_path  x1_bbox  y1_bbox  \\\n0  /kaggle/working/ccpd_subset_base/train/0252274...      213      480   \n1  /kaggle/working/ccpd_subset_base/train/0216235...      236      512   \n2  /kaggle/working/ccpd_subset_base/train/0320581...      220      466   \n3  /kaggle/working/ccpd_subset_base/train/0434051...      182      401   \n4  /kaggle/working/ccpd_subset_base/train/0314583...      190      473   \n\n   x2_bbox  y2_bbox plate_number  \n0      438      598      皖AZ339F  \n1      527      602      皖RWZ900  \n2      564      572      鄂A32QA6  \n3      532      536      皖APF418  \n4      512      578      浙ARD851  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>x1_bbox</th>\n      <th>y1_bbox</th>\n      <th>x2_bbox</th>\n      <th>y2_bbox</th>\n      <th>plate_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0252274...</td>\n      <td>213</td>\n      <td>480</td>\n      <td>438</td>\n      <td>598</td>\n      <td>皖AZ339F</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0216235...</td>\n      <td>236</td>\n      <td>512</td>\n      <td>527</td>\n      <td>602</td>\n      <td>皖RWZ900</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0320581...</td>\n      <td>220</td>\n      <td>466</td>\n      <td>564</td>\n      <td>572</td>\n      <td>鄂A32QA6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0434051...</td>\n      <td>182</td>\n      <td>401</td>\n      <td>532</td>\n      <td>536</td>\n      <td>皖APF418</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/ccpd_subset_base/train/0314583...</td>\n      <td>190</td>\n      <td>473</td>\n      <td>512</td>\n      <td>578</td>\n      <td>浙ARD851</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"#we split the dataset in 80/20 for training phase.\ndf_train, df_val = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\n\nprint(f\"Train set: {len(df_train)} img\")\nprint(f\"Val set:   {len(df_val)} img\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:32:33.257758Z","iopub.execute_input":"2025-07-20T13:32:33.258024Z","iopub.status.idle":"2025-07-20T13:32:33.271573Z","shell.execute_reply.started":"2025-07-20T13:32:33.258002Z","shell.execute_reply":"2025-07-20T13:32:33.270846Z"}},"outputs":[{"name":"stdout","text":"Train set: 40000 img\nVal set:   10000 img\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"export_yolo(df_train, \"train\", IMG_W, IMG_H)\nexport_yolo(df_val, \"val\", IMG_W, IMG_H)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:32:35.937325Z","iopub.execute_input":"2025-07-20T13:32:35.937711Z","iopub.status.idle":"2025-07-20T13:33:12.605981Z","shell.execute_reply.started":"2025-07-20T13:32:35.937688Z","shell.execute_reply":"2025-07-20T13:33:12.605168Z"}},"outputs":[{"name":"stdout","text":"TRAIN completed  40000 examples\nVAL completed  10000 examples\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# FASE 1: Iperparametri per il Warm-up (10 epoche)\nmy_hyp_warmup = {\n    # General\n    'lr0': 0.01,              # Initial learning-rate\n    'lrf': 0.1,               # Final OneCycleLR learning-rate (lr0 * lrf)\n    'momentum': 0.937,        # SGD momentum/Adam beta1\n    'weight_decay': 0.0005,   # Optimizer weight decay\n\n    # Warm-up\n    'warmup_epochs': 3.0,     # Warmup epochs \n    'warmup_momentum': 0.8,   # Warmup initial momentum\n    'warmup_bias_lr': 0.1,    # Warmup initial bias lr\n\n    # Loss balance & IoU\n    'box': 0.05,              # Box loss gain\n    'cls': 0.3,               # Cls loss gain (scale with pixels)\n    'cls_pw': 1.0,            # Cls BCELoss positive_weight\n    'obj': 1.0,               # Obj loss gain (scale with pixels)\n    'obj_pw': 1.0,            # Obj BCELoss positive_weight\n    'iou_t': 0.30,            # IoU training threshold\n    'anchor_t': 4.0,          # Anchor-multiple threshold\n    'fl_gamma': 0.0,          # Focal loss gamma \n\n    # Augmentation - color / geometry\n    'hsv_h': 0.015,           # Image HSV-Hue augmentation (fraction)\n    'hsv_s': 0.7,             # Image HSV-Saturation augmentation (fraction)\n    'hsv_v': 0.4,             # Image HSV-Value augmentation (fraction)\n    'degrees': 20.0,          # Image rotation (+/- deg)\n    'translate': 0.2,         # Image translation (+/- fraction)\n    'scale': 0.9,             # Image scale (+/- gain)\n    'shear': 20.0,            # Image shear (+/- deg)\n    'perspective': 0.001,     # Image perspective (+/- fraction), range 0-0.001\n\n    # Augmentation - flip & mix\n    'flipud': 0.0,            # Image flip up-down (probability)\n    'fliplr': 0.5,            # Image flip left-right (probability)\n    'mosaic': 0.0,            # <<< Image mosaic (probability) - DISATTIVATO\n    'mixup': 0.0,             # <<< Image mixup (probability) - DISATTIVATO\n    'copy_paste': 0.0         # <<< Segment copy-paste (probability) - DISATTIVATO\n}\n\n\nhyp_path_warmup = \"yolov5/data/hyps/my_ccpd_warmup.yaml\"\nos.makedirs(os.path.dirname(hyp_path_warmup), exist_ok=True)\nwith open(hyp_path_warmup, 'w') as f:\n    yaml.dump(my_hyp_warmup, f, sort_keys=False)\n\nprint(f\"File di iperparametri per la Fase 1 salvato in: {hyp_path_warmup}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:36:26.985502Z","iopub.execute_input":"2025-07-20T13:36:26.985832Z","iopub.status.idle":"2025-07-20T13:36:26.994798Z","shell.execute_reply.started":"2025-07-20T13:36:26.985813Z","shell.execute_reply":"2025-07-20T13:36:26.994010Z"}},"outputs":[{"name":"stdout","text":"File di iperparametri per la Fase 1 salvato in: yolov5/data/hyps/my_ccpd_warmup.yaml\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"#training phase A\n!wandb disabled\n!python -W ignore yolov5/train.py \\\n  --weights yolov5s.pt \\\n  --data yolov5/ccpd.yaml \\\n  --hyp yolov5/data/hyps/my_ccpd_warmup.yaml \\\n  --batch -1 \\\n  --epochs 10 \\\n  --img 416 \\\n  --name ccpd_warmup \\\n  --cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T13:36:39.102422Z","iopub.execute_input":"2025-07-20T13:36:39.103068Z","iopub.status.idle":"2025-07-20T14:25:08.913558Z","shell.execute_reply.started":"2025-07-20T13:36:39.103041Z","shell.execute_reply":"2025-07-20T14:25:08.912764Z"}},"outputs":[{"name":"stdout","text":"W&B disabled.\n\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2025-07-20 13:36:50.698622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753018610.899175    1648 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753018610.961877    1648 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=yolov5/ccpd.yaml, hyp=yolov5/data/hyps/my_ccpd_warmup.yaml, epochs=10, batch_size=-1, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5/data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=ccpd_warmup, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.3, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=20.0, translate=0.2, scale=0.9, shear=20.0, perspective=0.001, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n100%|███████████████████████████████████████| 14.1M/14.1M [00:00<00:00, 154MB/s]\n\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\nModel summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n\nTransferred 343/349 items from yolov5s.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 416\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.10G reserved, 0.05G allocated, 15.74G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n     7022326       6.737         0.168         20.95         38.12        (1, 3, 416, 416)                    list\n     7022326       13.47         0.245         16.52         24.38        (2, 3, 416, 416)                    list\n     7022326       26.95         0.445         16.53         38.82        (4, 3, 416, 416)                    list\n     7022326        53.9         0.881         17.93         29.95        (8, 3, 416, 416)                    list\n     7022326       107.8         1.527          28.1         41.59       (16, 3, 416, 416)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 136 for CUDA:0 12.72G/15.89G (80%) ✅\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0010625), 60 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\nsize\n  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/train... 40000 images, \u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/train.cache\n\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (12.0GB ram): 100%|██████████| 40000/40000 [01:07<00:00, 5\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/val... 10000 images, 0 ba\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/ccpd_yolo_dataset/labels/val.cache\n\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.0GB ram): 100%|██████████| 10000/10000 [00:37<00:00, 268.\u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.56 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\nPlotting labels to yolov5/runs/train/ccpd_warmup/labels.jpg... \nImage sizes 416 train, 416 val\nUsing 4 dataloader workers\nLogging results to \u001b[1myolov5/runs/train/ccpd_warmup\u001b[0m\nStarting training for 10 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        0/9      13.3G    0.05871    0.01111          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.881      0.896      0.851      0.221\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        1/9      13.4G    0.03591   0.006469          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.994      0.993      0.995       0.63\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        2/9      13.4G    0.02964   0.004265          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.995      0.998      0.995      0.608\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        3/9      13.4G    0.02546   0.003527          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.995      0.997      0.995      0.612\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        4/9      13.4G    0.02388   0.003309          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.996      0.997      0.993       0.59\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        5/9      13.4G    0.02235    0.00317          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.998      0.999      0.995      0.574\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        6/9      13.4G    0.02103   0.003063          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999      0.998      0.995      0.679\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        7/9      13.4G    0.02011    0.00297          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999      0.999      0.995      0.663\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        8/9      13.4G    0.01932   0.002906          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999      0.999      0.995      0.727\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n        9/9      13.4G    0.01865   0.002839          0         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999      0.999      0.995      0.733\n\n10 epochs completed in 0.742 hours.\nOptimizer stripped from yolov5/runs/train/ccpd_warmup/weights/last.pt, 14.3MB\nOptimizer stripped from yolov5/runs/train/ccpd_warmup/weights/best.pt, 14.3MB\n\nValidating yolov5/runs/train/ccpd_warmup/weights/best.pt...\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999      0.999      0.995      0.733\nResults saved to \u001b[1myolov5/runs/train/ccpd_warmup\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# FASE 2: \nmy_hyp_final = {\n    # General\n    'lr0': 0.01,              # Initial learning-rate\n    'lrf': 0.1,               # Final OneCycleLR learning-rate (lr0 * lrf)\n    'momentum': 0.937,        # SGD momentum/Adam beta1\n    'weight_decay': 0.0005,   # Optimizer weight decay\n\n    # Warm-up\n    'warmup_epochs': 3.0,     # Warmup epochs (fractions ok)\n    'warmup_momentum': 0.8,   # Warmup initial momentum\n    'warmup_bias_lr': 0.1,    # Warmup initial bias lr\n\n    # Loss balance & IoU\n    'box': 0.05,              # Box loss gain\n    'cls': 0.3,               # Cls loss gain (scale with pixels)\n    'cls_pw': 1.0,            # Cls BCELoss positive_weight\n    'obj': 1.0,               # Obj loss gain (scale with pixels)\n    'obj_pw': 1.0,            # Obj BCELoss positive_weight\n    'iou_t': 0.30,            # IoU training threshold        \n    'anchor_t': 4.0,          # Anchor-multiple threshold\n    'fl_gamma': 0.0,          # Focal loss gamma \n\n    # Augmentation - color (per DB, Weather)\n    'hsv_h': 0.015,           # Tonalità\n    'hsv_s': 0.7,             # Saturazione (per colori sbiaditi)\n    'hsv_v': 0.4,             # Luminosità (per scene troppo scure/chiare)\n\n    # Augmentation - geometry (per Rotate, Tilt, FN)\n    'degrees': 20.0,          # Aumentato per CCPD-Rotate e Tilt\n    'translate': 0.2,         # Variazione della posizione\n    'scale': 0.9,             # Range di scala ampio per CCPD-FN (targhe vicine/lontane)\n    'shear': 20.0,            # Aumentato per CCPD-Tilt\n    'perspective': 0.001,     # Per le inclinazioni di CCPD-Tilt\n\n    # Augmentation - flip & mix (per Challenge, Weather, FN)\n    'flipud': 0.0,\n    'fliplr': 0.5,\n    'mosaic': 1.0,            # <<< Per FN, Tilt, Rotate e Challenge\n    'mixup': 0.2,             # <<< Aumentato per DB e Weather\n    'copy_paste': 0.1\n}\n\nhyp_path_final = \"yolov5/data/hyps/my_ccpd_final.yaml\"\nos.makedirs(os.path.dirname(hyp_path_final), exist_ok=True)\nwith open(hyp_path_final, 'w') as f:\n    yaml.dump(my_hyp_final, f, sort_keys=False)\n\nprint(f\"File di iperparametri per la Fase 2 salvato in: {hyp_path_final}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T14:26:50.784232Z","iopub.execute_input":"2025-07-20T14:26:50.784537Z","iopub.status.idle":"2025-07-20T14:26:50.805152Z","shell.execute_reply.started":"2025-07-20T14:26:50.784509Z","shell.execute_reply":"2025-07-20T14:26:50.804514Z"}},"outputs":[{"name":"stdout","text":"File di iperparametri per la Fase 2 salvato in: yolov5/data/hyps/my_ccpd_final.yaml\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"!wandb disabled\n!python -W ignore yolov5/train.py \\\n  --weights yolov5/runs/train/ccpd_warmup/weights/last.pt \\\n  --data yolov5/ccpd.yaml \\\n  --hyp yolov5/data/hyps/my_ccpd_final.yaml \\\n  --batch -1 \\\n  --epochs 40 \\\n  --img 416 \\\n  --name ccpd_final \\\n  --cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T14:27:04.168060Z","iopub.execute_input":"2025-07-20T14:27:04.168830Z","iopub.status.idle":"2025-07-20T17:29:47.682767Z","shell.execute_reply.started":"2025-07-20T14:27:04.168806Z","shell.execute_reply":"2025-07-20T17:29:47.681870Z"}},"outputs":[{"name":"stdout","text":"W&B disabled.\n\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2025-07-20 14:27:13.714706: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753021633.737754    1765 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753021633.744559    1765 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/runs/train/ccpd_warmup/weights/last.pt, cfg=, data=yolov5/ccpd.yaml, hyp=yolov5/data/hyps/my_ccpd_final.yaml, epochs=40, batch_size=-1, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5/data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=ccpd_final, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.3, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=20.0, translate=0.2, scale=0.9, shear=20.0, perspective=0.001, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.2, copy_paste=0.1\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\nModel summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n\nTransferred 349/349 items from yolov5/runs/train/ccpd_warmup/weights/last.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 416\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.10G reserved, 0.05G allocated, 15.74G free\n      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n     7022326       6.737         0.168         20.88         32.82        (1, 3, 416, 416)                    list\n     7022326       13.47         0.245          17.6         23.98        (2, 3, 416, 416)                    list\n     7022326       26.95         0.445         17.55         37.46        (4, 3, 416, 416)                    list\n     7022326        53.9         0.881         19.11          27.8        (8, 3, 416, 416)                    list\n     7022326       107.8         1.527         28.15         41.47       (16, 3, 416, 416)                    list\n\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 136 for CUDA:0 12.72G/15.89G (80%) ✅\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0010625), 60 bias\n\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\nsize\n  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/train.cache... 40000 im\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (12.0GB ram): 100%|██████████| 40000/40000 [01:28<00:00, 4\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/val.cache... 10000 images\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.0GB ram): 100%|██████████| 10000/10000 [00:45<00:00, 217.\u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.56 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\nPlotting labels to yolov5/runs/train/ccpd_final/labels.jpg... \nImage sizes 416 train, 416 val\nUsing 4 dataloader workers\nLogging results to \u001b[1myolov5/runs/train/ccpd_final\u001b[0m\nStarting training for 40 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/39      13.3G    0.03275   0.009076          0         48        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.992          1      0.993      0.655\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/39      13.3G    0.02919   0.008066          0         52        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.997          1      0.995       0.69\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/39      13.3G    0.02706   0.007809          0         35        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.994      0.999      0.994      0.532\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/39      13.3G    0.02595    0.00774          0         53        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.992      0.999      0.994      0.627\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/39      13.3G    0.02511   0.007527          0         35        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.996      0.999      0.994      0.708\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/39      13.3G    0.02434   0.007424          0         37        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.996          1      0.995      0.572\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/39      13.3G     0.0238   0.007265          0         50        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000       0.97      0.978      0.962       0.41\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/39      13.3G    0.02326   0.007199          0         46        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.997      0.998      0.995       0.66\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/39      13.3G    0.02305   0.007181          0         32        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.998          1      0.995      0.638\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/39      13.3G    0.02264   0.007058          0         35        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.996      0.999      0.995       0.71\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/39      13.3G    0.02236   0.007044          0         50        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.998          1      0.995      0.659\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/39      13.3G    0.02211   0.006976          0         54        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.995      0.999      0.995      0.696\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/39      13.3G     0.0219   0.006922          0         38        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.995          1      0.995      0.657\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/39      13.3G    0.02165    0.00689          0         42        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.737\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/39      13.3G    0.02167   0.006907          0         37        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.998          1      0.995      0.704\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/39      13.3G    0.02135   0.006828          0         36        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995       0.72\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/39      13.3G    0.02125   0.006793          0         48        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.704\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/39      13.3G    0.02106   0.006717          0         31        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995       0.73\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/39      13.3G    0.02085   0.006721          0         52        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.729\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/39      13.3G    0.02082   0.006713          0         57        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.723\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/39      13.3G    0.02059   0.006652          0         38        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.998          1      0.995      0.735\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/39      13.3G    0.02045   0.006582          0         33        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.721\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/39      13.3G    0.02047   0.006651          0         45        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.723\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/39      13.3G    0.02026   0.006608          0         45        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.741\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/39      13.3G     0.0202   0.006569          0         53        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.727\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      25/39      13.3G    0.01999   0.006491          0         39        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.738\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      26/39      13.3G    0.01983   0.006501          0         35        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000          1          1      0.995      0.737\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      27/39      13.3G    0.01976   0.006489          0         43        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.747\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      28/39      13.3G    0.01969   0.006493          0         31        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.731\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      29/39      13.3G    0.01957    0.00639          0         40        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.739\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      30/39      13.3G    0.01946   0.006421          0         37        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995       0.74\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      31/39      13.3G    0.01926   0.006374          0         35        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000          1          1      0.995      0.743\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      32/39      13.3G    0.01916   0.006358          0         44        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000          1          1      0.995      0.745\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      33/39      13.3G    0.01905    0.00631          0         41        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.744\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      34/39      13.3G    0.01885   0.006288          0         36        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000          1          1      0.995      0.745\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      35/39      13.3G    0.01885   0.006248          0         45        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000          1          1      0.995      0.746\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      36/39      13.3G    0.01862   0.006221          0         49        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.747\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      37/39      13.3G    0.01849   0.006208          0         46        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995      0.749\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      38/39      13.3G    0.01835   0.006115          0         31        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995       0.75\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      39/39      13.3G    0.01821   0.006151          0         58        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995       0.75\n\n40 epochs completed in 2.977 hours.\nOptimizer stripped from yolov5/runs/train/ccpd_final/weights/last.pt, 14.3MB\nOptimizer stripped from yolov5/runs/train/ccpd_final/weights/best.pt, 14.3MB\n\nValidating yolov5/runs/train/ccpd_final/weights/best.pt...\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n                 Class     Images  Instances          P          R      mAP50   \n                   all      10000      10000      0.999          1      0.995       0.75\nResults saved to \u001b[1myolov5/runs/train/ccpd_final\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# **Test**","metadata":{}},{"cell_type":"code","source":"folder = \"/kaggle/working/ccpd_test\"\nrows = []\n\nfor root, _, files in os.walk(folder):\n    for fname in files:\n        if not fname.endswith(\".jpg\"):\n            continue\n\n        parts = fname[:-4].split(\"-\")\n        if len(parts) < 6:\n            continue\n\n        x1, y1, x2, y2 = split_bbox(parts[2])\n        plate = decode_plate(parts[4])\n        full_path = os.path.join(root, fname)\n\n        rows.append({\n            \"image_path\": full_path,\n            \"x1_bbox\": x1,\n            \"y1_bbox\": y1,\n            \"x2_bbox\": x2,\n            \"y2_bbox\": y2,\n            \"plate_number\": plate\n        })\n\ndf = pd.DataFrame(rows)\nprint(f\"Dataset created: {len(df)} rows\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:30:43.605027Z","iopub.execute_input":"2025-07-20T17:30:43.605339Z","iopub.status.idle":"2025-07-20T17:30:43.771935Z","shell.execute_reply.started":"2025-07-20T17:30:43.605311Z","shell.execute_reply":"2025-07-20T17:30:43.771346Z"}},"outputs":[{"name":"stdout","text":"Dataset created: 8000 rows\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                          image_path  x1_bbox  y1_bbox  \\\n0  /kaggle/working/ccpd_test/tilt/0741-32_42-174_...      174      333   \n1  /kaggle/working/ccpd_test/tilt/0545-14_31-198_...      198      449   \n2  /kaggle/working/ccpd_test/tilt/0508-30_30-280_...      280      415   \n3  /kaggle/working/ccpd_test/tilt/0305-16_44-226_...      226      472   \n4  /kaggle/working/ccpd_test/tilt/0743-29_14-424_...      424      330   \n\n   x2_bbox  y2_bbox plate_number  \n0      414      591      皖NAK326  \n1      492      604      晋E68B13  \n2      474      634      皖AQ6807  \n3      437      593      皖ASH205  \n4      685      568      皖AL180E  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>x1_bbox</th>\n      <th>y1_bbox</th>\n      <th>x2_bbox</th>\n      <th>y2_bbox</th>\n      <th>plate_number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/working/ccpd_test/tilt/0741-32_42-174_...</td>\n      <td>174</td>\n      <td>333</td>\n      <td>414</td>\n      <td>591</td>\n      <td>皖NAK326</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/working/ccpd_test/tilt/0545-14_31-198_...</td>\n      <td>198</td>\n      <td>449</td>\n      <td>492</td>\n      <td>604</td>\n      <td>晋E68B13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/working/ccpd_test/tilt/0508-30_30-280_...</td>\n      <td>280</td>\n      <td>415</td>\n      <td>474</td>\n      <td>634</td>\n      <td>皖AQ6807</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/working/ccpd_test/tilt/0305-16_44-226_...</td>\n      <td>226</td>\n      <td>472</td>\n      <td>437</td>\n      <td>593</td>\n      <td>皖ASH205</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/working/ccpd_test/tilt/0743-29_14-424_...</td>\n      <td>424</td>\n      <td>330</td>\n      <td>685</td>\n      <td>568</td>\n      <td>皖AL180E</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"#export_yolo now consider each subfolder for creating the dataset\ndef export_yolo(df_split, split_name, img_w, img_h):\n    base_img_dir = os.path.join(OUT_BASE, \"images\", split_name)\n    base_lbl_dir = os.path.join(OUT_BASE, \"labels\", split_name)\n\n    count = 0\n\n    for _, row in df_split.iterrows():\n        try:\n            if None in (row[\"x1_bbox\"], row[\"y1_bbox\"], row[\"x2_bbox\"], row[\"y2_bbox\"]):\n                continue\n       \n            x_center = (row[\"x1_bbox\"] + row[\"x2_bbox\"]) / 2 / img_w\n            y_center = (row[\"y1_bbox\"] + row[\"y2_bbox\"]) / 2 / img_h\n            width    = (row[\"x2_bbox\"] - row[\"x1_bbox\"]) / img_w\n            height   = (row[\"y2_bbox\"] - row[\"y1_bbox\"]) / img_h\n\n            yolo_line = f\"{CLASS_ID} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n\n            img_path = row[\"image_path\"]\n            base_name = os.path.basename(img_path)\n            name_no_ext = os.path.splitext(base_name)[0]\n\n            rel_subfolder = os.path.basename(os.path.dirname(img_path))\n\n            img_dir = os.path.join(base_img_dir, rel_subfolder)\n            lbl_dir = os.path.join(base_lbl_dir, rel_subfolder)\n            os.makedirs(img_dir, exist_ok=True)\n            os.makedirs(lbl_dir, exist_ok=True)\n\n            dst_img_path = os.path.join(img_dir, base_name)\n            shutil.copy2(img_path, dst_img_path)\n\n            label_path = os.path.join(lbl_dir, f\"{name_no_ext}.txt\")\n            with open(label_path, \"w\") as f:\n                f.write(yolo_line)\n\n            count += 1\n\n        except Exception as e:\n            print(f\"Error {row['image_path']}: {e}\")\n\n    print(f\"{split_name.upper()} compleated: {count} examples saved.\")\n    \nexport_yolo(df, \"test\", IMG_W, IMG_H)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:30:46.766904Z","iopub.execute_input":"2025-07-20T17:30:46.767617Z","iopub.status.idle":"2025-07-20T17:30:59.689486Z","shell.execute_reply.started":"2025-07-20T17:30:46.767594Z","shell.execute_reply":"2025-07-20T17:30:59.688878Z"}},"outputs":[{"name":"stdout","text":"TEST compleated: 8000 examples saved.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"base_dir = \"/kaggle/working/ccpd_yolo_dataset\"\nimg_root = os.path.join(base_dir, \"images\", \"test\")\nlbl_root = os.path.join(base_dir, \"labels\", \"test\")\ntemplate_yaml_path = \"/kaggle/working/yolov5/ccpd_temp.yaml\"\nweights_path = \"/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt\"\n\n# All subdir (tilt, blur, ..)\nsubdirs = [d for d in os.listdir(img_root) if os.path.isdir(os.path.join(img_root, d))]\n\nfor sub in subdirs:\n    img_dir = os.path.join(\"images/test\", sub)  \n    lbl_dir = os.path.join(\"labels/test\", sub)\n\n    yaml_content = f\"\"\"\\\n                    path: {base_dir}\n                    train: {img_dir}  # not used\n                    val: {img_dir}\n                    nc: 1\n                    names: ['plate']\n                    \"\"\"\n    with open(template_yaml_path, \"w\") as f:\n        f.write(yaml_content)\n\n    print(f\" Subset: {sub}\")\n    !python /kaggle/working/yolov5/val.py \\\n    --weights \"{weights_path}\" \\\n    --data    \"{template_yaml_path}\" \\\n    --imgsz   640 \\\n    --task    val  \\\n    --iou-thres  0.7 \\\n    --verbose \\\n    --save-txt --save-conf \\\n    --name    test_{sub} \\\n    --project /kaggle/working/yolov5/runs/test \\\n    --exist-ok","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:32:23.887267Z","iopub.execute_input":"2025-07-20T17:32:23.888064Z","iopub.status.idle":"2025-07-20T17:35:03.940206Z","shell.execute_reply.started":"2025-07-20T17:32:23.888037Z","shell.execute_reply":"2025-07-20T17:35:03.939437Z"}},"outputs":[{"name":"stdout","text":" Subset: tilt\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_tilt, exist_ok=True, half=False, dnn=False\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/tilt.cache... 1000 i\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.988       0.99      0.995      0.654\nSpeed: 0.2ms pre-process, 2.4ms inference, 1.6ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_tilt\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_tilt/labels\n Subset: challenge\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_challenge, exist_ok=True, half=False, dnn=False\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/challenge.cache... 1\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.989       0.98      0.992      0.657\nSpeed: 0.1ms pre-process, 2.3ms inference, 1.5ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_challenge\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_challenge/labels\n Subset: weather\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_weather, exist_ok=True, half=False, dnn=False\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/weather.cache... 100\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.998          1      0.995      0.787\nSpeed: 0.1ms pre-process, 2.2ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_weather\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_weather/labels\n Subset: db\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_db, exist_ok=True, half=False, dnn=False\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/db.cache... 1000 ima\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.924      0.899      0.936      0.498\nSpeed: 0.1ms pre-process, 2.4ms inference, 1.6ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_db\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_db/labels\n Subset: fn\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_fn, exist_ok=True, half=False, dnn=False\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/fn.cache... 1000 ima\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.973      0.959      0.969      0.628\nSpeed: 0.1ms pre-process, 2.3ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_fn\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_fn/labels\n Subset: base\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_base, exist_ok=True, half=False, dnn=False\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/base.cache... 1000 i\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.996          1      0.995      0.743\nSpeed: 0.1ms pre-process, 2.3ms inference, 1.4ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_base\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_base/labels\n Subset: rotate\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_rotate, exist_ok=True, half=False, dnn=False\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/rotate.cache... 1000\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.992      0.992      0.994      0.709\nSpeed: 0.1ms pre-process, 2.3ms inference, 1.5ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_rotate\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_rotate/labels\n Subset: blur\n\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/yolov5/ccpd_temp.yaml, weights=['/kaggle/working/yolov5/runs/train/ccpd_final/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=True, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/kaggle/working/yolov5/runs/test, name=test_blur, exist_ok=True, half=False, dnn=False\nYOLOv5 🚀 v7.0-422-g2540fd4c Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\nFusing layers... \nModel summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/ccpd_yolo_dataset/labels/test/blur.cache... 1000 i\u001b[0m\n                 Class     Images  Instances          P          R      mAP50   \n                   all       1000       1000      0.982      0.954      0.975       0.59\nSpeed: 0.3ms pre-process, 2.3ms inference, 1.5ms NMS per image at shape (32, 3, 640, 640)\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\nResults saved to \u001b[1m/kaggle/working/yolov5/runs/test/test_blur\u001b[0m\n1000 labels saved to /kaggle/working/yolov5/runs/test/test_blur/labels\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"#!zip -r ccpd_results.zip /kaggle/working/yolov5/runs/test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **METRIC COMPUTATION**","metadata":{}},{"cell_type":"code","source":"base_dir  = \"/kaggle/working/ccpd_yolo_dataset\"\nruns_root = \"/kaggle/working/yolov5/runs/test\"\n\nsubdirs = [\n    d for d in os.listdir(os.path.join(base_dir, \"images\", \"test\"))\n    if os.path.isdir(os.path.join(base_dir, \"images\", \"test\", d))\n]\n\n\ndef yolo_to_xyxy(xc, yc, w, h):\n    return [xc - w/2, yc - h/2, xc + w/2, yc + h/2]\n\ndef load_boxes(txt_path):\n    if not txt_path.exists():\n        return torch.empty((0, 4))\n    boxes = []\n    for line in txt_path.read_text().strip().splitlines():\n        _, xc, yc, w, h, *rest = map(float, line.split())\n        boxes.append(yolo_to_xyxy(xc, yc, w, h))\n    return torch.tensor(boxes) if boxes else torch.empty((0, 4))\n\ndef metrics_one_subset(sub, thr=0.7):\n    pred_dir = Path(runs_root) / f\"test_{sub}\" / \"labels\"\n    gt_dir   = Path(base_dir)   / \"labels\" / \"test\" / sub\n\n    tp, fp, total_gt, correct_img = 0, 0, 0, 0   \n\n    for gt_file in gt_dir.glob(\"*.txt\"):\n        gt_boxes   = load_boxes(gt_file)               \n        pred_boxes = load_boxes(pred_dir / gt_file.name)\n        total_gt  += len(gt_boxes)                     \n\n        # accuracy\n        if len(gt_boxes) and len(pred_boxes):\n            if (box_iou(gt_boxes, pred_boxes).max() >= thr):\n                correct_img += 1\n                \n        # TP / FP box \n        if len(gt_boxes) and len(pred_boxes):\n            ious = box_iou(gt_boxes, pred_boxes)\n            tp  += (ious.max(dim=1).values > thr).sum().item()\n            fp  += (ious.max(dim=0).values <= thr).sum().item()\n        elif len(pred_boxes):  \n            fp += len(pred_boxes)\n\n    fn = total_gt - tp\n    recall    = tp / total_gt if total_gt else 0.0\n    precision = tp / (tp + fp) if (tp + fp) else 0.0\n    accuracy  = correct_img / total_gt if total_gt else 0.0 \n\n    return {\n        \"subset\": sub,\n        \"GT\": total_gt,\n        \"TP\": tp,\n        \"FP\": fp,\n        \"FN\": fn,\n        \"Recall_IoU>0.7\":    round(recall,    4),\n        \"Precision_IoU>0.7\": round(precision, 4),\n        \"Accuracy_img_IoU>0.7\": round(accuracy, 4)\n    }\n\nresults = [metrics_one_subset(sub) for sub in subdirs]\ndf = pd.DataFrame(results)\n\ndf = df[[\"subset\", \"GT\", \"TP\", \"FP\", \"FN\",\n         \"Recall_IoU>0.7\", \"Precision_IoU>0.7\", \"Accuracy_img_IoU>0.7\"]]\n\nprint(df.to_string(index=False))\ndf.to_csv(\"/kaggle/working/iou0.7_metrics.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:35:38.195184Z","iopub.execute_input":"2025-07-20T17:35:38.195933Z","iopub.status.idle":"2025-07-20T17:35:43.127265Z","shell.execute_reply.started":"2025-07-20T17:35:38.195908Z","shell.execute_reply":"2025-07-20T17:35:43.126482Z"}},"outputs":[{"name":"stdout","text":"   subset   GT  TP    FP  FN  Recall_IoU>0.7  Precision_IoU>0.7  Accuracy_img_IoU>0.7\n     tilt 1000 956  5625  44           0.956             0.1453                 0.956\nchallenge 1000 980 10633  20           0.980             0.0844                 0.980\n  weather 1000 997  7507   3           0.997             0.1172                 0.997\n       db 1000 926 11550  74           0.926             0.0742                 0.926\n       fn 1000 930 11253  70           0.930             0.0763                 0.930\n     base 1000 996  8220   4           0.996             0.1081                 0.996\n   rotate 1000 986  4738  14           0.986             0.1723                 0.986\n     blur 1000 949 10746  51           0.949             0.0811                 0.949\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"base_dir      = \"/kaggle/working/ccpd_yolo_dataset\"\nimg_dir_rel   = \"images/test\"                 \ntemplate_yaml = \"/kaggle/working/yolov5/ccpd.yaml\"\nbatch_size    = 5 # the paper use batch size 5 for fps computation\n\nyaml_text = f\"\"\"\\\npath: {base_dir}\ntrain: {img_dir_rel}  # not used\nval:   {img_dir_rel}\nnc: 1\nnames: ['plate']\n\"\"\"\nwith open(template_yaml, \"w\") as f:\n    f.write(yaml_text)\n\ndef count_imgs(root):                \n    exts = {\".jpg\", \".jpeg\"}\n    return sum(1 for p in Path(root).rglob('*') if p.suffix.lower() in exts)\n\nn_imgs = count_imgs(Path(base_dir) / img_dir_rel)\nif n_imgs == 0:\n    raise RuntimeError(\"Error: No img found\")\n\nprint(f\"Starting clock for {n_imgs} imgs (batch={batch_size})\")\n\nt0 = time.perf_counter() #clock starting\n\ncmd = [\n    sys.executable, \"-W\", \"ignore\",                  \n    \"/kaggle/working/yolov5/val.py\",\n    \"--weights\", weights_path,\n    \"--data\",    template_yaml,\n    \"--imgsz\",   \"640\",\n    \"--batch\",   str(batch_size),\n    \"--task\",    \"val\",\n    \"--iou-thres\",\"0.7\",\n    \"--conf-thres\",\"0.001\",\n    \"--name\",    \"ccpd_global\",\n    \"--project\", \"/kaggle/working/yolov5/runs/test\",\n    \"--exist-ok\"\n]\nresult = subprocess.run(cmd, capture_output=True, text=True)\nt1 = time.perf_counter() #stop counter\n\n#\nelapsed = t1 - t0            # total seconds\nfps     = n_imgs / elapsed   # fps computation\n\nprint(f\"Total img   : {n_imgs}\")\nprint(\"Formula              : FPS = num_images / elapsed_seconds\")\nprint(f\"Computation              : {n_imgs} / {elapsed:.2f} s  =  {fps:,.1f} FPS\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:37:09.043629Z","iopub.execute_input":"2025-07-20T17:37:09.043929Z","iopub.status.idle":"2025-07-20T17:38:33.951219Z","shell.execute_reply.started":"2025-07-20T17:37:09.043907Z","shell.execute_reply":"2025-07-20T17:38:33.950402Z"}},"outputs":[{"name":"stdout","text":"Starting clock for 8000 imgs (batch=5)\nTotal img   : 8000\nFormula              : FPS = num_images / elapsed_seconds\nComputation              : 8000 / 84.85 s  =  94.3 FPS\n","output_type":"stream"}],"execution_count":32}]}