{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5-PDLPR algorithm\n",
    "---\n",
    "## Task\n",
    "The objective of this project is to design and implement a deep learning-based system for license plate recognition, following the methodology outlined by [Tao et al.](https://www.mdpi.com/1424-8220/24/9/2791) (2024). The proposed solution is structured as a two-stage pipeline, leveraging the strengths of different neural network architectures to address the distinct subtasks involved in the recognition process.\n",
    "\n",
    "- In the **first stage**, a **YOLOv5** model is employed for license plate detection, allowing for fast and accurate localization of the plate region within vehicle images, even under challenging environmental conditions.\n",
    "\n",
    "- In the **second stage**, the cropped plate region is passed to a specialized recognition model based on the **PDLPR** architecture. This model is responsible for decoding the sequence of alphanumeric characters on the plate, effectively treating the task as a sequence prediction problem.\n",
    "\n",
    "The integration of these two components aims to deliver a robust and efficient system for plate recognition and reconstruction suitable for deployment in real-world scenarios.\n",
    "\n",
    "---\n",
    "## Main Objectives\n",
    "\n",
    "- Implement a simple baseline, train and evaluate it with the metrics used by [Tao et al.](https://www.mdpi.com/1424-8220/24/9/2791) (2024).\n",
    "\n",
    "- Implement the proposed model by [Tao et al.](https://www.mdpi.com/1424-8220/24/9/2791) (2024), composed of the YOLOv5 and PDLPR models, and evaluate it.\n",
    "\n",
    "- Compare the performance of the proposed model with the baseline, underlining why the proposed model works better or not on recognizing and reconstructing the car plates.\n",
    "\n",
    "---\n",
    "## Dataset\n",
    "\n",
    "[CCPD](https://github.com/detectRecog/CCPD) (Chinese City Parking Dataset) is a large and diverse open-source dataset of Chinese license plates. Each image contains one license plate, and each plate includes seven characters:\n",
    "\n",
    "- The **first character** represents a **provincial administrative region**.\n",
    "- The **second character** is a **letter**.\n",
    "- The **remaining five characters** are either **letters or numbers** (excluding the characters \"I\" and \"O\").\n",
    "\n",
    "The dataset is divided into nine sub-datasets, each representing different challenges such as illumination, tilt, distance, and weather conditions. These are described below:\n",
    "\n",
    "| Sub-Dataset        | Description |\n",
    "|--------------------|-------------|\n",
    "| **CCPD-Base**      | Standard images with the only shared feature being the presence of a license plate. |\n",
    "| **CCPD-DB**        | Dark, uneven, or extremely bright illumination in the license plate (LP) area. |\n",
    "| **CCPD-FN**        | Captured from varying distances — either relatively far or near. |\n",
    "| **CCPD-Rotate**    | Large horizontal tilt (20°–50°) and vertical tilt from -10° to 10°. |\n",
    "| **CCPD-Tilt**      | Extreme horizontal (15°–45°) and vertical tilt (15°–45°). |\n",
    "| **CCPD-Blur**      | Blurry images, mostly due to hand jitter during capture. |\n",
    "| **CCPD-Weather**   | Images taken in adverse weather: rain, snow, or fog. |\n",
    "| **CCPD-Challenge** | The most difficult and complex images for license plate detection and recognition (LPDR). |\n",
    "| **CCPD-NP**        | Images of new cars with no visible license plate. |\n",
    "\n",
    "\n",
    "For model training and evaluation:\n",
    "\n",
    "- **Training set**: 49,000 randomly selected samples from the  CCPD-Base sub-dataset.\n",
    "- **Validation set**: 1,000 samples from the same  CCPD-Base sub-dataset.\n",
    "- **Testing set**: Six challenging sub-datasets were used for evaluation:\n",
    "  -  CCPD-DB \n",
    "  -  CCPD-FN \n",
    "  -  CCPD-Rotate \n",
    "  -  CCPD-Tilt \n",
    "  -  CCPD-Weather \n",
    "  -  CCPD-Challenge \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## Data Augmentation\n",
    "\n",
    "To address the limited size of the training set and to improve generalization across challenging test sub-datasets, we applied extensive **data augmentation**. This helps prevent overfitting and enhances the model’s robustness to various real-world conditions.\n",
    "\n",
    "We designed **ad-hoc transformations** tailored to the characteristics of the different CCPD sub-datasets. The augmentations simulate conditions such as camera distortion, motion, lighting, and environmental effects. The applied transformations include:\n",
    "\n",
    "- Affine transformations (rotation, shear, translation)\n",
    "- Perspective distortion\n",
    "- Gaussian blur\n",
    "- Motion blur\n",
    "- Color dithering\n",
    "- Changes in contrast, saturation, and brightness\n",
    "- Image quality degradation (e.g., compression artifacts)\n",
    "- Simulated fog and nighttime conditions\n",
    "- Other visual perturbations\n",
    "\n",
    "The figure below illustrates examples of augmented license plate images:\n",
    "\n",
    "![Data Augmentation](figures/augmentation.png)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## Baseline\n",
    "\n",
    "**TODO**: Breve descriziomn della detection\n",
    "\n",
    "The baseline recognizer uses a **CNN + BiLSTM + Linear** architecture to convert a license plate image into a sequence of character logits. A convolutional backbone extracts spatial features from input images of shape `[B, 3, 48, 144]`, producing a feature map of shape `[B, 256, 12, 36]`.\n",
    "\n",
    "The width dimension is treated as the temporal axis and fed to a 2-layer **Bidirectional LSTM**. The model selects 7 fixed time steps to produce 7 character predictions, each mapped to one of 68 possible classes through a linear layer. Training is performed using **Cross Entropy Loss**.\n",
    "\n",
    "---\n",
    "## YOLOvs-PDLPR\n",
    "\n",
    "### YOLOv5\n",
    "\n",
    "[YOLOv5](https://github.com/ultralytics/yolov5)\n",
    "\n",
    "### PDLPR\n",
    "\n",
    "The PDLPR model architecture is illustrated in the figure below:\n",
    "![The overall framework of the license plate recognition algorithm.](figures/pdlpr.png)\n",
    "It comprises three primary modules:\n",
    "\n",
    "1. **Improved Global Feature Extractor (IGFE)**  \n",
    "   - Input: License plate images resized to `48 × 144` pixels.  \n",
    "   - Process: Extracts features and converts them into a feature vector of dimensions `512 × 6 × 18`.  \n",
    "\n",
    "2. **Encoder Module**  \n",
    "   - **Position Encoder**: Encodes the position of the feature map and adds it to the image feature vector.  \n",
    "   - **Multi-Head Attention**: Further encodes the combined vector to produce an output feature vector.  \n",
    "\n",
    "3. **Parallel Decoder Module**  \n",
    "   - Utilizes **Multi-Head Attention** to decode the encoder's output feature vector.  \n",
    "   - Predicts the final license plate sequence.  \n",
    "\n",
    "The training is performed using **CTC Loss**.\n",
    "\n",
    "---\n",
    "## Metric\n",
    "\n",
    "Since each image in the CCPD dataset contains only a **single license plate (LP)**, we focus on **accuracy** rather than recall. Each detector is allowed to predict **only one bounding box per image**.\n",
    "\n",
    "The evaluation is divided into three parts:\n",
    "\n",
    "- **Detection**:  For each image, the detector outputs a single bounding box. A detection is considered **correct** if the Intersection over Union (IoU) with the ground truth bounding box is greater than 70% (**IoU>0.7**)\n",
    "\n",
    " - **Recognition**: A recognition is considered correct only if **all characters** in the license plate are **correctly recognized**.\n",
    "\n",
    "- **Combined Detection and Recognition**:  A result is considered fully correct when the predicted bounding box has **IoU > 0.6**, and **all characters** in the license plate are correctly recognized.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Structure\n",
    "```\n",
    "PDLPR-algorithm/\n",
    "├── src/                         # Core source code\n",
    "│   ├── attention.py             # Self-attention and cross-attention modules\n",
    "│   ├── augmentation.py          # Data augmentation transformations\n",
    "│   ├── baseline.py              # Baseline license plate recognizer (CNN + BiLSTM)\n",
    "│   ├── decoder.py               # Decoder module for the PDLPR architecture\n",
    "│   ├── encoder.py               # Encoder module for the PDLPR architecture\n",
    "│   ├── feature\\_extractor.py     # IGFE\n",
    "│   ├── pdlpr.py                 # Main PDLPR model structure\n",
    "│   ├── trainer.py               # Training and evaluation utilities\n",
    "│   ├── utility.py               # Helper functions: decoding, dataset creation, etc.\n",
    "│   └── README.md                # Documentation for baseline and PDLPR components\n",
    "├── presentation/                # Slides with results and analysis\n",
    "├── figures/                     # Figures used in README and presentation\n",
    "├── pdlpr-main.ipynb             # Notebook for training and evaluating PDLPR\n",
    "├── baseline-recognition.ipynb   # Notebook for training the baseline recognizer\n",
    "└── README.md                    # Project overview and documentation\n",
    "```\n",
    "---\n",
    "## Results\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. Tao, L., Hong, S., Lin, Y., Chen, Y., He, P. and Tie, Z. (2024). [A Real-Time License Plate Detection and Recognition Model in Unconstrained Scenarios](https://www.mdpi.com/1424-8220/24/9/2791). *Sensors*, 24(9), 2791.\n",
    "\n",
    "\n",
    "2. Xu, Z.; Yang, W.; Meng, A.; Lu, N.; Huang, H.; Ying, C.; Huang, L. [Towards end-to-end license plate detection and recognition: A large dataset and baseline](https://openaccess.thecvf.com/content_ECCV_2018/papers/Zhenbo_Xu_Towards_End-to-End_License_ECCV_2018_paper.pdf). In Proceedings of the European Conference on Computer Vision (ECCV), Munich, Germany, 8–14 September 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
